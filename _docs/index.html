<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-12-18">
<meta name="keywords" content="social networks, stochastic blockmodels, hierarchical Bayesian stochastic blockmodels, Bayesian inference, generative models">

<title>Inferential Network Clustering with Hierarchical Bayesian Stochastic Blockmodels</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="Inferential Network Clustering with Hierarchical Bayesian Stochastic Blockmodels">
<meta name="citation_keywords" content="social networks, stochastic blockmodels, hierarchical Bayesian stochastic blockmodels, Bayesian inference, generative models">
<meta name="citation_author" content="Pierson Browne">
<meta name="citation_author" content="Tyler Crick">
<meta name="citation_author" content="John McLevey">
<meta name="citation_editor" content="John McLevey and John Scott and Peter J Carrington (eds)">
<meta name="citation_publication_date" content="2023-12-18">
<meta name="citation_cover_date" content="2023-12-18">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2023-12-18">
<meta name="citation_language" content="en">
<meta name="citation_inbook_title" content="The Sage Handbook of Social Network Analysis (Volume 2)">
<meta name="citation_reference" content="citation_title=Introduction;,citation_author=John Scott;,citation_author=John McLevey;,citation_author=Peter J Carrington;,citation_editor=John McLevey;,citation_editor=John Scott;,citation_editor=Peter J Carrington;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=The SAGE handbook of social network analysis (volume 2);">
<meta name="citation_reference" content="citation_title=Structural cohesion and cohesive subgroups;,citation_author=James Moody;,citation_author=Peter J Mucha;,citation_editor=John McLevey;,citation_editor=John Scott;,citation_editor=Peter J Carrington;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=The SAGE handbook of social network analysis (volume 2);">
<meta name="citation_reference" content="citation_title=Blockmodelling, positions, and roles;,citation_author=Patrick Dorien;,citation_author=Anuška Ferligoj;,citation_author=Vladimir Batagelj;,citation_editor=John McLevey;,citation_editor=John Scott;,citation_editor=Peter J Carrington;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=The SAGE handbook of social network analysis (volume 2);">
<meta name="citation_reference" content="citation_title=Building stochastic blockmodels;,citation_author=Carolyn Anderson;,citation_author=Stanley Wasserman;,citation_author=Katherine Faust;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=1-2;,citation_volume=14;,citation_journal_title=Social networks;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Blockmodels: Developments and prospects;,citation_author=Phipps Arabie;,citation_author=Scott A Boorman;,citation_author=others;,citation_editor=Herschel C. Hudson;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_inbook_title=Classifying social data: New applications of analytic methods for social science research;">
<meta name="citation_reference" content="citation_title=Constructing blockmodels: How and why;,citation_author=Phipps Arabie;,citation_author=Scott A Boorman;,citation_author=Paul Levitt;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_issue=1;,citation_volume=17;,citation_journal_title=Journal of mathematical psychology;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=The paradox of corrupt networks: An analysis of organizational crime at enron;,citation_author=Brandy Aven;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=4;,citation_volume=26;,citation_journal_title=Organization Science;,citation_publisher=Informs;">
<meta name="citation_reference" content="citation_title=Fast unfolding of communities in large networks;,citation_author=Vincent Blondel;,citation_author=Jean-Loup Guillaume;,citation_author=Renaud Lambiotte;,citation_author=Etienne Lefebvre;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=10;,citation_volume=2008;,citation_journal_title=Journal of statistical mechanics: theory and experiment;,citation_publisher=IOP Publishing;">
<meta name="citation_reference" content="citation_title=Social structure from multiple networks. II. Role structures;,citation_author=Scott A Boorman;,citation_author=Harrison White;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_issue=6;,citation_volume=81;,citation_journal_title=American journal of sociology;,citation_publisher=University of Chicago Press;">
<meta name="citation_reference" content="citation_title=An algorithm for clustering relational data with applications to social network analysis and comparison with multidimensional scaling;,citation_author=Ronald Breiger;,citation_author=Scott A Boorman;,citation_author=Phipps Arabie;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_issue=3;,citation_volume=12;,citation_journal_title=Journal of mathematical psychology;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Bernoulli’s fallacy: Statistical illogic and the crisis of modern science;,citation_author=Aubrey Clayton;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Theoretical sociology;,citation_author=Randall Collins;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;">
<meta name="citation_reference" content="citation_title=The dynamic stochastic topic block model for dynamic networks with textual edges;,citation_author=Marco Corneli;,citation_author=Charles Bouveyron;,citation_author=Pierre Latouche;,citation_author=Fabrice Rossi;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=29;,citation_journal_title=Statistics and Computing;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Probability, frequency and reasonable expectation;,citation_author=Richard Cox;,citation_publication_date=1946;,citation_cover_date=1946;,citation_year=1946;,citation_issue=1;,citation_volume=14;,citation_journal_title=American journal of physics;,citation_publisher=American Association of Physics Teachers;">
<meta name="citation_reference" content="citation_title=Exploration of communication networks from the enron email corpus;,citation_author=Jana Diesner;,citation_author=Kathleen Carley;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=SIAM international conference on data mining: Workshop on link analysis, counterterrorism and security, newport beach, CA;">
<meta name="citation_reference" content="citation_title=On random graphs i;,citation_author=P Erdös;,citation_author=A Rényi;,citation_publication_date=1959;,citation_cover_date=1959;,citation_year=1959;,citation_volume=6;,citation_journal_title=Publicationes Mathematicae Debrecen;">
<meta name="citation_reference" content="citation_title=The relational basis of attitudes.;,citation_author=Bonnie Erickson;,citation_editor=Barry Wellman;,citation_editor=Stephen Berkowitz;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_inbook_title=Social structures: A network approach;">
<meta name="citation_reference" content="citation_title=The analysis of sociograms using matrix algebra;,citation_author=Leon Festinger;,citation_publication_date=1949;,citation_cover_date=1949;,citation_year=1949;,citation_issue=2;,citation_volume=2;,citation_journal_title=Human relations;,citation_publisher=Sage Publications Sage CA: Thousand Oaks, CA;">
<meta name="citation_reference" content="citation_title=Community detection in graphs;,citation_author=Santo Fortunato;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=3-5;,citation_volume=486;,citation_journal_title=Physics reports;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Structural cohesion and equivalence explanations of social homogeneity;,citation_author=Noah Friedkin;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=3;,citation_volume=12;,citation_journal_title=Sociological Methods &amp;amp;amp; Research;,citation_publisher=Sage Publications;">
<meta name="citation_reference" content="citation_title=The minimum description length principle;,citation_author=Peter D Grünwald;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Network analysis with the enron email corpus;,citation_author=JS Hardin;,citation_author=Ghassan Sarkis;,citation_author=PC Urc;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=2;,citation_volume=23;,citation_journal_title=Journal of Statistics Education;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Stochastic blockmodels: First steps;,citation_author=Paul Holland;,citation_author=Kathryn Blackmond Laskey;,citation_author=Samuel Leinhardt;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_issue=2;,citation_volume=5;,citation_journal_title=Social networks;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Probability theory: The logic of science;,citation_author=Edwin Jaynes;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Introducing the enron corpus.;,citation_author=Bryan Klimt;,citation_author=Yiming Yang;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=45;,citation_conference_title=CEAS;">
<meta name="citation_reference" content="citation_title=Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters;,citation_author=Jure Leskovec;,citation_author=Kevin Lang;,citation_author=Anirban Dasgupta;,citation_author=Michael Mahoney;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=6;,citation_journal_title=Internet Mathematics;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=A primer on blockmodeling procedure;,citation_author=John Light;,citation_author=Nicholas Mullins;,citation_editor=Paul Holland;,citation_editor=Samuel Leinhardt;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_inbook_title=Perspectives on social network research;">
<meta name="citation_reference" content="citation_title=Structural equivalence of individuals in social networks;,citation_author=Francois Lorrain;,citation_author=Harrison White;,citation_publication_date=1971;,citation_cover_date=1971;,citation_year=1971;,citation_issue=1;,citation_volume=1;,citation_journal_title=The Journal of mathematical sociology;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=A method of matrix analysis of group structure;,citation_author=Duncan Luce;,citation_author=Albert Perry;,citation_publication_date=1949;,citation_cover_date=1949;,citation_year=1949;,citation_issue=2;,citation_volume=14;,citation_journal_title=Psychometrika;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Information theory, inference and learning algorithms;,citation_author=David JC MacKay;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Analyzing the ENRON communication network using agent-based simulation;,citation_author=Shinako Matsuyama;,citation_author=Takao Terano;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=7;,citation_volume=3;,citation_journal_title=Journal of Networks;">
<meta name="citation_reference" content="citation_title=Statistical rethinking: A bayesian course with examples in R and STAN;,citation_author=Richard McElreath;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=The theory of social structure;,citation_author=Siegfried Frederick Nadel;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=8;">
<meta name="citation_reference" content="citation_title=Improved mutual information measure for clustering, classification, and community detection;,citation_author=Mark Newman;,citation_author=George Cantwell;,citation_author=Jean-Gabriel Young;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=4;,citation_volume=101;,citation_journal_title=Physical Review E;,citation_publisher=APS;">
<meta name="citation_reference" content="citation_title=Estimation and prediction for stochastic blockstructures;,citation_author=Krzysztof Nowicki;,citation_author=Tom AB Snijders;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=455;,citation_volume=96;,citation_journal_title=Journal of the American statistical association;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Bayesian stochastic blockmodeling;,citation_author=Tiago Peixoto;,citation_editor=Patrick Doreian;,citation_editor=Vladimir Batagelj;,citation_editor=Anuska Ferligoj;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_inbook_title=Advances in network clustering and blockmodeling;">
<meta name="citation_reference" content="citation_title=Descriptive vs. Inferential community detection in networks: Pitfalls, myths and half-truths;,citation_author=Tiago Peixoto;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=Elements in the Structure and Dynamics of Complex Networks;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Efficient monte carlo and greedy heuristic for the inference of stochastic block models;,citation_author=Tiago Peixoto;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=89;,citation_journal_title=Physical Review E;,citation_publisher=APS;">
<meta name="citation_reference" content="citation_title=Revealing consensus and dissensus between network partitions;,citation_author=Tiago Peixoto;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_volume=11;,citation_journal_title=Physical Review X;,citation_publisher=APS;">
<meta name="citation_reference" content="citation_title=Exponential random graph models for social networks;,citation_author=Garry Robins;,citation_editor=John Scott;,citation_editor=Peter J Carrington;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_inbook_title=The SAGE handbook of social network analysis;">
<meta name="citation_reference" content="citation_title=We gave you 3 million russian troll tweets. Here’s what you’ve found so far, 2018;,citation_author=Oliver Roeder;,citation_fulltext_html_url=https://fivethirtyeight.com/features/what-we-found-in-3-million-russian-troll-tweets/;,citation_publisher=FiveThirtyEight;">
<meta name="citation_reference" content="citation_title=V-measure: A conditional entropy-based external cluster evaluation measure;,citation_author=Andrew Rosenberg;,citation_author=Julia Hirschberg;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the 2007 joint conference on empirical methods in natural language processing and computational natural language learning (EMNLP-CoNLL);">
<meta name="citation_reference" content="citation_title=A mathematical theory of communication;,citation_author=Claude Shannon;,citation_publication_date=1948;,citation_cover_date=1948;,citation_year=1948;,citation_issue=3;,citation_volume=27;,citation_journal_title=The Bell system technical journal;,citation_publisher=Nokia Bell Labs;">
<meta name="citation_reference" content="citation_title=The graph-tool python library;,citation_author=Tiago Peixoto;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_fulltext_html_url=http://figshare.com/articles/graph_tool/1164194;,citation_doi=10.6084/m9.figshare.1164194;,citation_journal_title=figshare;">
<meta name="citation_reference" content="citation_title=Enron data;,citation_author=Arne Hendrik Ruhe;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_publisher=www.ahschulz.de/enron-email-data/;">
<meta name="citation_reference" content="citation_title=Inside russia’s domestic disinformation ecosystem;,citation_author=Perri Grace;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://inkstickmedia.com/inside-russias-domestic-disinformation-ecosystem/;,citation_publisher=Inkstick;">
<meta name="citation_reference" content="citation_title=Four truths about bots;,citation_author=Common Thread;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://blog.twitter.com/common-thread/en/topics/stories/2021/four-truths-about-bots;,citation_publisher=Twitter;">
<meta name="citation_reference" content="citation_title=Estimation and prediction for stochastic blockmodels for graphs with latent block structure;,citation_author=Tom AB Snijders;,citation_author=Krzysztof Nowicki;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=1;,citation_volume=14;,citation_journal_title=Journal of classification;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=The disinformation shift: From foreign to domestic;,citation_author=Alistair Somerville;,citation_author=Jonas Heerin;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_journal_title=Georgetown Journal of International Affairs;">
<meta name="citation_reference" content="citation_title=From louvain to leiden: Guaranteeing well-connected communities;,citation_author=Vincent Traag;,citation_author=Ludo Waltman;,citation_author=Nees Jan Van Eck;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=1;,citation_volume=9;,citation_journal_title=Scientific reports;,citation_publisher=Nature Publishing Group UK London;">
<meta name="citation_reference" content="citation_title=Enron dataset research: E-mail relevance classification;,citation_author=Victoria VanBuren;,citation_author=David Villarreal;,citation_author=Thomas McMillen;,citation_author=Andrew Minnicks;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Stochastic blockmodels for directed graphs;,citation_author=Yuchung Wang;,citation_author=George Wong;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_issue=397;,citation_volume=82;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Stochastic a posteriori blockmodels: Construction and assessment;,citation_author=Stanley Wasserman;,citation_author=Carolyn Anderson;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_issue=1;,citation_volume=9;,citation_journal_title=Social networks;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Social network analysis: Methods and applications;,citation_author=Stanley Wasserman;,citation_author=Katherine Faust;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;">
<meta name="citation_reference" content="citation_title=Graph and semigroup homomorphisms on networks of relations;,citation_author=Douglas White;,citation_author=Karl Reitz;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_issue=2;,citation_volume=5;,citation_journal_title=Social Networks;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Social structure from multiple networks. I. Blockmodels of roles and positions;,citation_author=Harrison White;,citation_author=Scott A Boorman;,citation_author=Ronald Breiger;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_issue=4;,citation_volume=81;,citation_journal_title=American journal of sociology;,citation_publisher=University of Chicago Press;">
<meta name="citation_reference" content="citation_title=Discovery of email communication networks from the enron corpus with a genetic algorithm using social network analysis;,citation_author=Garnett Wilson;,citation_author=Wolfgang Banzhaf;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=2009 IEEE congress on evolutionary computation;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Statistical inference of assortative community structures;,citation_author=Lizhi Zhang;,citation_author=Tiago Peixoto;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=4;,citation_volume=2;,citation_journal_title=Physical Review Research;,citation_publisher=APS;">
<meta name="citation_reference" content="citation_title=Where do priors come from? Applying guidelines to construct informative priors in small sample research;,citation_author=Mariëlle Zondervan-Zwijnenburg;,citation_author=Margot Peeters;,citation_author=Sarah Depaoli;,citation_author=Rens Van de Schoot;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=4;,citation_volume=14;,citation_journal_title=Research in Human Development;,citation_publisher=Taylor &amp;amp;amp; Francis;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Inferential Network Clustering with Hierarchical Bayesian Stochastic Blockmodels</h1>
            <p class="subtitle lead">Published as Chapter 30 in John McLevey, John Scott, and Peter J. Carrington (eds) 2023. <em>The Sage Handbook of Social Network Analysis (Volume 2)</em>. London, UK: Sage.</p>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Pierson Browne <a href="mailto:pbrowne@uwaterloo.ca" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-3073-2603" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        University of Waterloo
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Tyler Crick <a href="mailto:tcrick@uwaterloo.ca" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0003-1559-9936" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        University of Waterloo
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">John McLevey <a href="mailto:john.mclevey@uwaterloo.ca" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-8512-1308" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        University of Waterloo
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">December 18, 2023</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="index.pdf"><i class="bi bi-file-pdf"></i>PDF</a></p></div></div></div>
    </div>


    <div>
      <div class="keywords">
        <div class="block-title">Keywords</div>
        <p>social networks, stochastic blockmodels, hierarchical Bayesian stochastic blockmodels, Bayesian inference, generative models</p>
      </div>
    </div>

    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#foundational-ideas" id="toc-foundational-ideas" class="nav-link" data-scroll-target="#foundational-ideas"><span class="header-section-number">2</span> Foundational Ideas</a>
  <ul class="collapse">
  <li><a href="#equivalence-and-blockmodels" id="toc-equivalence-and-blockmodels" class="nav-link" data-scroll-target="#equivalence-and-blockmodels"><span class="header-section-number">2.1</span> Equivalence and Blockmodels</a>
  <ul class="collapse">
  <li><a href="#stochastic-equivalence-and-blockmodels" id="toc-stochastic-equivalence-and-blockmodels" class="nav-link" data-scroll-target="#stochastic-equivalence-and-blockmodels"><span class="header-section-number">2.1.1</span> Stochastic Equivalence and Blockmodels</a></li>
  </ul></li>
  <li><a href="#the-logic-of-bayesian-inference-and-latent-variable-models" id="toc-the-logic-of-bayesian-inference-and-latent-variable-models" class="nav-link" data-scroll-target="#the-logic-of-bayesian-inference-and-latent-variable-models"><span class="header-section-number">2.2</span> The Logic of Bayesian Inference and Latent Variable Models</a></li>
  <li><a href="#the-synthesis-hierarchical-bayesian-stochastic-blockmodels" id="toc-the-synthesis-hierarchical-bayesian-stochastic-blockmodels" class="nav-link" data-scroll-target="#the-synthesis-hierarchical-bayesian-stochastic-blockmodels"><span class="header-section-number">2.3</span> The Synthesis: Hierarchical Bayesian Stochastic Blockmodels</a>
  <ul class="collapse">
  <li><a href="#model-selection-using-minimum-description-length" id="toc-model-selection-using-minimum-description-length" class="nav-link" data-scroll-target="#model-selection-using-minimum-description-length"><span class="header-section-number">2.3.1</span> Model Selection using Minimum Description Length</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#empirical-examples" id="toc-empirical-examples" class="nav-link" data-scroll-target="#empirical-examples"><span class="header-section-number">3</span> Empirical Examples</a>
  <ul class="collapse">
  <li><a href="#the-enron-email-network" id="toc-the-enron-email-network" class="nav-link" data-scroll-target="#the-enron-email-network"><span class="header-section-number">3.1</span> The Enron Email Network</a></li>
  <li><a href="#disinformation-on-twitter-ira-tweets" id="toc-disinformation-on-twitter-ira-tweets" class="nav-link" data-scroll-target="#disinformation-on-twitter-ira-tweets"><span class="header-section-number">3.2</span> Disinformation on Twitter: IRA Tweets</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">4</span> Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">5</span> References</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Methods and models for network clustering have long been at the core of social network analysis <span class="citation" data-cites="mclevey2023shsna1intro">(see <a href="#ref-mclevey2023shsna1intro" role="doc-biblioref">Scott, McLevey, and Carrington 2024</a>)</span>. Since the 1970s, network clustering has developed along two deeply intertwined conceptual paths: one focusing on cohesive subgroups and assortative community structure <span class="citation" data-cites="moody2023shsna2cohesion">(e.g., see <a href="#ref-moody2023shsna2cohesion" role="doc-biblioref">Moody and Mucha 2024</a>)</span>, the other focusing on equivalence, social roles, and structural positions <span class="citation" data-cites="dorien2023shsna3bpr">(e.g., see <a href="#ref-dorien2023shsna3bpr" role="doc-biblioref">Dorien, Ferligoj, and Batagelj 2024</a>)</span>.</p>
<p>Early research on social cohesion sought to identify fully connected subgroups in friendship networks <span class="citation" data-cites="festinger1949analysis luce1949method">(<a href="#ref-festinger1949analysis" role="doc-biblioref">Festinger 1949</a>; <a href="#ref-luce1949method" role="doc-biblioref">Luce and Perry 1949</a>)</span>, while later work would focus more on social homophily or heterogeneity among closely connected groups <span class="citation" data-cites="friedkin1984structural collins1988theoretical erickson1988relational">(<a href="#ref-friedkin1984structural" role="doc-biblioref">Friedkin 1984</a>; <a href="#ref-collins1988theoretical" role="doc-biblioref">Collins 1988</a>; <a href="#ref-erickson1988relational" role="doc-biblioref">Erickson 1988</a>)</span>. Increases in the size and complexity of network data has driven the development of many new methods for measuring social cohesion <span class="citation" data-cites="stanley1994social">(<a href="#ref-stanley1994social" role="doc-biblioref">Wasserman and Faust 1994</a>)</span>, and for scaling up to large networks in reasonable timespans. The well-known and oft-employed Louvain algorithm for optimizing modularity <span class="citation" data-cites="blondel2008fast">(<a href="#ref-blondel2008fast" role="doc-biblioref">Blondel et al. 2008</a>)</span> and the improved Leiden algorithm <span class="citation" data-cites="traag2019louvain">(<a href="#ref-traag2019louvain" role="doc-biblioref">Traag, Waltman, and Van Eck 2019</a>)</span> are noteworthy contributions to this line of work.</p>
<p>The other path, which we are primarily concerned with in this chapter, seeks to cluster nodes based on a structural and/or probabilistic definition of node “equivalence,” such as having identical sets of ties to other nodes. However defined, the concept of equivalence enables researchers to reduce complex networks into simplified representations of the relationships between positions, roles, or “blocks.” We provide a brief high-level overview of this work below; interested readers can find more a more detailed account of role theory and positional analysis in <span class="citation" data-cites="dorien2023shsna3bpr">Dorien, Ferligoj, and Batagelj (<a href="#ref-dorien2023shsna3bpr" role="doc-biblioref">2024</a>)</span>, which focuses on generalized blockmodeling. In most of this chapter, we will focus on a probabilistic approach to blockmodeling: the hierarchical Bayesian stochastic blockmodel.</p>
<p>This chapter in organized in two parts. The purpose of the first is to introduce foundational ideas related to (a) <a href="#equivalence-and-blockmodels">equivalence and blockmodeling</a>, (b) <a href="#the-logic-of-bayesian-inference-and-latent-variable-models">Bayesian inference and latent variable models</a>, and finally (c) the <a href="#the-synthesis-hierarchical-bayesian-stochastic-blockmodels">synthesis of these ideas in the form of Bayesian stochastic blockmodels (BSBMs)</a>. In the second part of the chapter, we focus on two <a href="#empirical-examples">empirical examples</a> that illustrate some important considerations when developing and interpreting BSBMs.</p>
</section>
<section id="foundational-ideas" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Foundational Ideas</h1>
<section id="equivalence-and-blockmodels" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="equivalence-and-blockmodels"><span class="header-section-number">2.1</span> Equivalence and Blockmodels</h2>
<p>Unlike network clustering methods that are primarily concerned with cohesion and connectivity, blockmodels are ultimately concerned with the concept of equivalence. In a classic paper, <span class="citation" data-cites="lorrain1971structural">Lorrain and White (<a href="#ref-lorrain1971structural" role="doc-biblioref">1971</a>)</span> introduced in the idea of “structural equivalence” as follows:</p>
<blockquote class="blockquote">
<p><span class="math inline">\(a\)</span> is structurally equivalent to <span class="math inline">\(b\)</span> if a relates to every object <span class="math inline">\(x\)</span> of [the set of nodes] <span class="math inline">\(C\)</span> in exactly the same ways as <span class="math inline">\(b\)</span> does. From the point of view of the logic of the structure, then, <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are absolutely equivalent, they are substitutable <span class="citation" data-cites="lorrain1971structural">(<a href="#ref-lorrain1971structural" role="doc-biblioref">Lorrain and White 1971, 63</a>)</span>.</p>
</blockquote>
<p>From the start, this work has been highly influenced by anthropological role theory, specifically the work of SF <span class="citation" data-cites="nadel2013theory">Nadel (<a href="#ref-nadel2013theory" role="doc-biblioref">[1957] 2013</a>)</span>, who emphasized the inherent complexity of measuring social roles and positions. The overarching goal of early work on blockmodels was to algorithmically reduce complex networks to simplified models of the relationships between structurally distinct social roles, or “positions.” Any possible partition produced by a blockmodel could represent an imperfect proxy of the role structure. <span class="citation" data-cites="white1976social">H. White, Boorman, and Breiger (<a href="#ref-white1976social" role="doc-biblioref">1976</a>)</span> acknowledge this explicitly in their classic paper: “the blockmodels of this paper can be said to identify positions, but only in an elementary sense” (p.&nbsp;734). With <span class="citation" data-cites="nadel2013theory">Nadel (<a href="#ref-nadel2013theory" role="doc-biblioref">[1957] 2013</a>)</span>, they contend that data on many types of ties are needed to apprehend social structure, and it is therefore important to consider multiple models <span class="citation" data-cites="white1976social">(<a href="#ref-white1976social" role="doc-biblioref">H. White, Boorman, and Breiger 1976</a>)</span>. <span class="citation" data-cites="robins2011exponential">Robins (<a href="#ref-robins2011exponential" role="doc-biblioref">2011</a>)</span> echoes this sentiment, suggesting that although social networks are “built by social processes that are ongoing and multiple,” patterns in network data “provide evidence from which we may infer something of the social processes that build the network” (484). In short, it is not necessarily the case that structurally equivalent nodes perform the same social roles, and no single blockmodel can hope to capture the totality of a social dynamic within a given network.</p>
<p>The earliest blockmodels used a variety of deterministic approaches to partition empirical networks into clusters of equivalent nodes <span class="citation" data-cites="arabie1982blockmodels arabie1978constructing boorman1976social breiger1975algorithm light1979primer white1976social stanley1994social">(<a href="#ref-arabie1982blockmodels" role="doc-biblioref">Arabie, Boorman, et al. 1982</a>; <a href="#ref-arabie1978constructing" role="doc-biblioref">Arabie, Boorman, and Levitt 1978</a>; <a href="#ref-boorman1976social" role="doc-biblioref">Boorman and White 1976</a>; <a href="#ref-breiger1975algorithm" role="doc-biblioref">Breiger, Boorman, and Arabie 1975</a>; <a href="#ref-light1979primer" role="doc-biblioref">Light and Mullins 1979</a>; <a href="#ref-white1976social" role="doc-biblioref">H. White, Boorman, and Breiger 1976</a>; <a href="#ref-stanley1994social" role="doc-biblioref">Wasserman and Faust 1994</a>)</span>. However, the requirement that nodes be perfectly interchangeable was proven to be too strict in practice, especially given the complexity of social relationships and the imperfections of data collection and measurement. This led to further innovations in blockmodeling techniques <span class="citation" data-cites="dorien2023shsna3bpr">(see <a href="#ref-dorien2023shsna3bpr" role="doc-biblioref">Dorien, Ferligoj, and Batagelj 2024</a>)</span> as well as more relaxed criteria for equivalence, such as “regular equivalence” <span class="citation" data-cites="white1983graph">(<a href="#ref-white1983graph" role="doc-biblioref">D. White and Reitz 1983</a>)</span> and “stochastic equivalence.” The latter is the basis of an approach that has come to be known as the “stochastic blockmodel” (SBM).</p>
<section id="stochastic-equivalence-and-blockmodels" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="stochastic-equivalence-and-blockmodels"><span class="header-section-number">2.1.1</span> Stochastic Equivalence and Blockmodels</h3>
<p>Unlike deterministic blockmodels, which require perfect or near-perfect interchangeability between nodes in a block, SBMs partition networks into blocks of stochastically equivalent nodes <span class="citation" data-cites="anderson1992building holland1983stochastic nowicki2001estimation snijders1997estimation wang1987stochastic wasserman1987stochastic">(<a href="#ref-anderson1992building" role="doc-biblioref">Anderson, Wasserman, and Faust 1992</a>; <a href="#ref-holland1983stochastic" role="doc-biblioref">Holland, Laskey, and Leinhardt 1983</a>; <a href="#ref-nowicki2001estimation" role="doc-biblioref">Nowicki and Snijders 2001</a>; <a href="#ref-snijders1997estimation" role="doc-biblioref">Snijders and Nowicki 1997</a>; <a href="#ref-wang1987stochastic" role="doc-biblioref">Wang and Wong 1987</a>; <a href="#ref-wasserman1987stochastic" role="doc-biblioref">Wasserman and Anderson 1987</a>)</span>. In an SBM, blocks are organized so as to maximize the likelihood of block membership conditional on hypothesized edge probabilities, and therefore do not need to be perfectly uniform.</p>
<p>For a simple stochastic blockmodel to describe directed network <span class="math inline">\(A\)</span> with <span class="math inline">\(N\)</span> nodes, we need three pieces of information:</p>
<ol type="1">
<li><span class="math inline">\(E\)</span>, the total number of edges between nodes in <span class="math inline">\(A\)</span>;</li>
<li><span class="math inline">\(b\)</span>, a vector of length <span class="math inline">\(N\)</span> containing a block assignment for each node in the network where each <span class="math inline">\(b_n\in{1...B}\)</span>, where <span class="math inline">\(B\)</span> is the number of distinct blocks;</li>
<li><span class="math inline">\(p_{rs}\)</span>, a <span class="math inline">\(B\)</span>-by-<span class="math inline">\(B\)</span> matrix where <span class="math inline">\(r,s\in{1...B}\)</span>, describing the probability of observing an edge from any node in group <span class="math inline">\(r\)</span> to any node in group <span class="math inline">\(s\)</span>.</li>
</ol>
<p>Any two nodes in the same block are taken to be stochastically equivalent, which implies that any node in a given block will send ties to other nodes with the same probability as any other node in the same block. This is as true of the inter-block edges (<span class="math inline">\(p_{rs}\)</span>, <span class="math inline">\(r \neq s\)</span>) which is the probability that a node in one block sends an edge to a node in a different block, as it is of within-block edges (<span class="math inline">\(p_{rs}\)</span>, <span class="math inline">\(r=s\)</span>) where a node sends an edge to another node in the same block. It also implies that SBMs can identify blocks in which the nodes do not share any edges with one another, which is not the case for network clustering methods focused on cohesion (e.g., modularity-based algorithms such as Louvain and Leiden).</p>
<p>Fitting an SBM to an observed network requires determining the number of non-empty blocks to use and then partitioning the nodes (<span class="math inline">\(b\)</span>) accordingly. Since the matrix of edge probabilities (<span class="math inline">\(p_{rs}\)</span>) is determined by the block partition (<span class="math inline">\(b\)</span>), each possible permutation of b can be viewed as a possible explanation of the data.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Each of these explanations is assigned a likelihood (i.e., a probability that it is the ‘correct’ explanation), with likelier explanations of the data being assigned more weight than less likely explanations.</p>
<p>With some empirical networks, an SBM may not initially appear to produce results that differ meaningfully from those produced by community detection algorithms based on notions of cohesion rather than equivalence. In fact, certain configurations of the SBM can be coaxed into producing plausible partitions along similar lines as cohesion-based methods <span class="citation" data-cites="zhang2020statistical">(<a href="#ref-zhang2020statistical" role="doc-biblioref">Zhang and Peixoto 2020</a>)</span>. Closer inspection of the two should, however, dispel any notion that they are the same.</p>
<p>Consider the case of a random graph with an arbitrary number of nodes, a number of edges placed between nodes completely at random, and whose density falls somewhere between ‘dense’ and ‘sparse’ (such as an Edros-Renyi graph with a middling <span class="math inline">\(p\)</span> <span class="citation" data-cites="Erdos1959pmd">(<a href="#ref-Erdos1959pmd" role="doc-biblioref">Erdös and Rényi 1959</a>)</span>). In most such generated networks, traditional modularity-based methods such as Louvain are prone to identifying ‘communities’ from random noise <span class="citation" data-cites="peixoto2019bayesian">(<a href="#ref-peixoto2019bayesian" role="doc-biblioref">Peixoto 2019</a>)</span>. Blockmodel-based methods do not. The key point here is that ‘traditional’ community detection algorithms seek to understand networks <em>as they are observed</em>, whereas SBMs seek to understand <em>how networks came to be</em>, or <em>how they are generated</em>. In this sense, we can describe most traditional community detection techniques as descriptive <span class="citation" data-cites="peixoto2023descriptive">(<a href="#ref-peixoto2023descriptive" role="doc-biblioref">Peixoto 2023</a>)</span> and SBMs as inferential or generative.</p>
<p>Currently, descriptive approaches to network clustering are more widely used than inferential approaches. This is not necessarily a problem, as neither description nor inference enjoy any monopoly on the truth – in network science or otherwise – nor does one predominate the other in terms of applicability and utility. Descriptive forms of network clustering are invaluable for identifying certain features of an observed network, such as determining which edges are the most vital to community cohesion <span class="citation" data-cites="moody2023shsna2cohesion">(e.g., <a href="#ref-moody2023shsna2cohesion" role="doc-biblioref">Moody and Mucha 2024</a>)</span>. However, inferential approaches should be used to answer inferential questions, and network analyses concerned with tie formation and other unobserved generative processes that generate those networks necessarily involve inference <span class="citation" data-cites="peixoto2023descriptive">(<a href="#ref-peixoto2023descriptive" role="doc-biblioref">Peixoto 2023</a>)</span>.</p>
<p><span class="citation" data-cites="peixoto2023descriptive">Peixoto (<a href="#ref-peixoto2023descriptive" role="doc-biblioref">2023</a>)</span> has proposed a ‘litmus test’ that is helpful in determining whether an inferential approach should be used. The idea is a simple one: after partitioning a network into groups, we learn that our network was generated randomly. Does this alter the utility of our partition? If so, then it is likely that an inferential approach is necessary and descriptive approaches are inappropriate. If not, then it is likely that an inferential approach is not necessary and descriptive approaches are appropriate. In other words, if the generative process that gave rise to the observed network is relevant, then we need an inferential approach; if not, description is likely to be as appropriate, if not moreso.</p>
<p>Bayesian approaches to blockmodeling are particularly effective at partitioning networks given some representation of unobserved generative processes and, unlike many other approaches to blockmodeling, can determine the most appropriate number of blocks to account for a given network. Before getting into the details of Bayesian stochastic blockmodels (BSBMs), we’ll offer a brief overview of Bayesian inference and latent variable models for readers who are new to Bayesian statistics. Other readers should feel free to skip to the subsequent section.</p>
</section>
</section>
<section id="the-logic-of-bayesian-inference-and-latent-variable-models" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="the-logic-of-bayesian-inference-and-latent-variable-models"><span class="header-section-number">2.2</span> The Logic of Bayesian Inference and Latent Variable Models</h2>
<p>At its core, the Bayesian approach to inference uses data to update knowledge about one or more unobserved random variables <span class="citation" data-cites="mcelreath2020statistical">(<a href="#ref-mcelreath2020statistical" role="doc-biblioref">McElreath 2020</a>)</span>. This is accomplished via Bayes’ ubiquitous theorem, which states that the probability of an event <span class="math inline">\(A\)</span> conditional on another event <span class="math inline">\(B\)</span> is equal to the probability of <span class="math inline">\(B\)</span> conditional on <span class="math inline">\(A\)</span> multiplied by the unconditional probability of <span class="math inline">\(A\)</span> divided by the unconditional probability of <span class="math inline">\(B\)</span>. The foregoing can be encapsulated as such:</p>
<p><span class="math display">\[
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
\]</span></p>
<p>While Bayes’ theorem is widely accepted and applied across all statistical paradigms and disciplines, Bayesian inference distinguishes itself by using probability to describe logically-informed states of belief with respect to a given proposition. By way of contrast: the other major statistical paradigm, Frequentism, only permits the use of probability for events that can be sampled from among a population or repeated a theoretically infinite number of times, and thus does not view probability as compatible with statements about hypotheses, propositions, or states of belief <span class="citation" data-cites="clayton2021bernoulli">(<a href="#ref-clayton2021bernoulli" role="doc-biblioref">Clayton 2021</a>)</span>.</p>
<p>Readers familiar with Frequentist inference will know that the standard approach to ordinary least-squares (OLS) regression modelling, for example, stipulates that the relationship between a dependent variable (<span class="math inline">\(y\)</span>) and one or more independent variables (<span class="math inline">\(X\)</span>) is governed by a commensurate number of ‘parameters.’ In the simplest case, there is one parameter for each independent variable (<span class="math inline">\(\beta\)</span>) plus one parameter for the intercept (<span class="math inline">\(\alpha\)</span>), and the value of each is considered ‘fixed’ but unknown. Frequentist doctrine demands this; since parameter values cannot be sampled from, they do not have a frequency. They are true, or they are not. As such, Frequentist tests of statistical significance are configured to assess the plausibility of the observed data assuming the ‘null’ hypothesis (indicating ‘no difference’ or ‘no correlation’) is true. If the data is deemed unlikely enough (with the threshold, <span class="math inline">\(\alpha\)</span>, set pre-experimentally), the null is ‘rejected’ in favour of the data-determined ‘alternative’ hypothesis.</p>
<p>In the Bayesian paradigm, unobserved random variables in a model are conceptualized as latent variables, information about which can be encoded using probability distributions.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Rather than treating unobserved variables as fully unknown but with an assumed fixed value (as the Frequentist paradigm does for its parameters), Bayesian inference generally places ‘weakly informative’ distributions over its latent variables and then updates them using observed data.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>These distributions (known as ‘priors’, see below) are designed to be consistent with the knowledge researchers have about the latent variables before confronting them (and the rest of the model) with empirical data.</p>
<p>Each of the possible values a latent variable can take can be thought of as an individual ‘hypothesis’ about the value of that variable (e.g.&nbsp;the hypothesis that <span class="math inline">\(β\)</span>=0.59).<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> Bayesian inference seeks to describe the relative plausibility of all such hypotheses (which we’ll represent using <span class="math inline">\(H\)</span>) conditional upon a model and observed evidence (the latter of which we’ll represent with <span class="math inline">\(E\)</span>). This can be accomplished via Bayes’ theorem, which in this setting establishes that the probability of a hypothesis (<span class="math inline">\(H\)</span>) given some evidence (<span class="math inline">\(E\)</span>) is equal to the likelihood of that evidence given some hypothesis, multiplied by the unconditional probability of the hypothesis, divided by the unconditional probability of the evidence. Returning to Bayes’ theorem, but with the new symbols subbed in, we get:</p>
<p><span class="math display">\[
P(H|E)=\frac{P(E|H)P(H)}{P(E)}
\]</span></p>
<p>Each of the components in the forgoing expression is individually named:</p>
<ul>
<li><span class="math inline">\(P(H|E)\)</span> is the probability of a given hypothesis conditional upon the observed evidence. This is our quantity of interest, and it is known as the ‘Posterior Probability’ or ‘Inferential Probability’ <span class="citation" data-cites="clayton2021bernoulli">(<a href="#ref-clayton2021bernoulli" role="doc-biblioref">Clayton 2021</a>)</span>.</li>
<li><span class="math inline">\(P(E|H)\)</span> is referred to as the ‘Likelihood’ or ‘Sampling Probability’ of the data <span class="citation" data-cites="clayton2021bernoulli">(<a href="#ref-clayton2021bernoulli" role="doc-biblioref">Clayton 2021</a>)</span>. Likelihood in the Bayesian context is generally identical to that employed in the classical or Frequentist paradigms. It measures the probability of observing the evidence we did observe under the assumption that the hypothesis is true.</li>
<li><span class="math inline">\(P(H)\)</span> is called the ‘Prior’, and it represents our extant knowledge about the hypothesis before observing the data. Bayesian models treat priors as latent variables whose probability distributions are logically determined by the information available to the researcher <span class="citation" data-cites="cox1946probability jaynes2003probability">(<a href="#ref-cox1946probability" role="doc-biblioref">Cox 1946</a>; <a href="#ref-jaynes2003probability" role="doc-biblioref">Jaynes 2003</a>)</span>. While some may baulk at the inclusion of prior information, the use of a prior is essential for producing a posterior probability.</li>
<li><span class="math inline">\(P(E)\)</span> stands for the unconditional probability of the evidence and is sometimes referred to as the “Bayes Denominator” or the “Marginal Probability of the Data.” In many applied settings, this value is difficult to conceptualize and impossible to compute analytically. Fortunately, it only serves to normalize the product in the numerator (ensuring that all posterior probabilities sum to 1), and sampling-based techniques such as MCMC largely obviate the need to know it directly <span class="citation" data-cites="mcelreath2020statistical">(<a href="#ref-mcelreath2020statistical" role="doc-biblioref">McElreath 2020</a>)</span>.</li>
</ul>
<p>The Bayesian use of latent variables confers a great many advantages over the Frequentist adherence to parameter values. For the purposes of this chapter, the most salient advantage is that Bayesian latent variables are never reduced to a single point estimate: at all times, they are configured so as to contain complete descriptions of their probability mass (in the case of discrete variables) or probability density (in the case of continuous variable). This permits Bayesian inference to sustain consideration of multiple plausible values for any given latent variable, weighted proportionally to their posterior probability. The Frequentist approach, conversely, identifies a single value that uniquely maximizes likelihood and discards all others.</p>
<p>Latent variables also permit Bayesian models to run as well ‘forwards’ as they do ‘backwards.’ What we mean by this is that any well-specified Bayesian model is as well-suited for inferential purposes (‘backwards’) as it is for simulation (‘forwards’).<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> The inferential mode – as discussed above – uses data to update prior distributions over a model’s latent variables using the likelihood of the data, which produces a posterior distribution for each latent variable. The simulative mode draws samples from the joint distribution of the model’s latent variables to produce a synthetic dataset – this can be done using prior information alone (before observing data), or with the latent variables’ posterior distributions.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>Some, in fact, have gone as far as to use latent variables as a sort of grand unifying principle, arguing that even observed data is simply a special case of a probability distribution <span class="citation" data-cites="mcelreath2020statistical">(<a href="#ref-mcelreath2020statistical" role="doc-biblioref">McElreath 2020</a>)</span>.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> This view is consistent with the Bayesian paradigm’s treatment of measurement error and missing data: the former uses the observed value as a parameter for a distribution representing uncertainty, and the latter treats the missing value as a latent variable with a weakly informative distribution determined by observed values from the same case <span class="citation" data-cites="mcelreath2020statistical">(<a href="#ref-mcelreath2020statistical" role="doc-biblioref">McElreath 2020</a>)</span>. In this sense, almost all aspects of a Bayesian model – priors, posteriors, data, and parameters – take the form of latent variables with differing degrees of uncertainty encoded in their distributions.</p>
</section>
<section id="the-synthesis-hierarchical-bayesian-stochastic-blockmodels" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="the-synthesis-hierarchical-bayesian-stochastic-blockmodels"><span class="header-section-number">2.3</span> The Synthesis: Hierarchical Bayesian Stochastic Blockmodels</h2>
<p>Now that we are armed with the foundational ideas motivating blockmodeling and the Bayesian estimation of latent variables, we may proceed to their synthesis. As this is intended to be an accessible introduction, we have opted to minimize the technical details and encourage those interested in developing a deeper understanding of SMB-family models to consult foundational and cutting-edge texts on the subject <span class="citation" data-cites="snijders1997estimation nowicki2001estimation peixoto2019bayesian zhang2020statistical peixoto2023descriptive">(e.g., <a href="#ref-snijders1997estimation" role="doc-biblioref">Snijders and Nowicki 1997</a>; <a href="#ref-nowicki2001estimation" role="doc-biblioref">Nowicki and Snijders 2001</a>; <a href="#ref-peixoto2019bayesian" role="doc-biblioref">Peixoto 2019</a>, <a href="#ref-peixoto2023descriptive" role="doc-biblioref">2023</a>; <a href="#ref-zhang2020statistical" role="doc-biblioref">Zhang and Peixoto 2020</a>)</span>.</p>
<p>The Bayesian approach to blockmodeling involves building a generative model and using it to assess the likelihood of the observed network (<span class="math inline">\(A\)</span>) conditional on the range of possible hypotheses about the latent variables <span class="citation" data-cites="peixoto2019bayesian">(<a href="#ref-peixoto2019bayesian" role="doc-biblioref">Peixoto 2019</a>)</span>. By constraining our generative model so that it adheres to the observed network’s node and inter-block degree counts, the number of latent variables estimated shrinks from several to just one: <span class="math inline">\(b\)</span>.</p>
<p>Fundamentally, we are interested in determining the probability that a given node partition vector <span class="math inline">\(b\)</span> of length <span class="math inline">\(N\)</span> – which partitions the nodes of network <span class="math inline">\(A\)</span> into a number of blocks (<span class="math inline">\(B\)</span>), with each block consisting of stochastically equivalent nodes – was responsible for generating network <span class="math inline">\(A\)</span>. In the now-familiar language of Bayes’ theorem, we arrive at the following:</p>
<p><span class="math display">\[
P(b|A) = \frac{P(A|b)P(b)}{P(A)}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(A\)</span>: an <span class="math inline">\(N\)</span>-by-<span class="math inline">\(N\)</span> adjacency matrix, where each entry <span class="math inline">\(A_{i,j}\)</span> indicates the presence or absence of an edge between node <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> (in an undirected network, <span class="math inline">\(A\)</span> is symmetric. In a network without self-loops, the diagonal of <span class="math inline">\(A\)</span> is 0).</li>
<li><span class="math inline">\(N\)</span>: the number of nodes in network <span class="math inline">\(A\)</span>.</li>
<li><span class="math inline">\(B\)</span>: the number of blocks in a given partition <span class="math inline">\(b\)</span>.</li>
<li><span class="math inline">\(b\)</span>: a vector of length <span class="math inline">\(N\)</span> that indexes the nodes in the network, where <span class="math inline">\(b_i\in{1 ...B}\)</span> and <span class="math inline">\(i\in{1 ...N}\)</span>. Each permutation of <span class="math inline">\(b\)</span> represents one possible partition of the network.</li>
<li><span class="math inline">\(P(b|A)\)</span>: the posterior probability, or – equivalently – the probability of a partition <span class="math inline">\(b\)</span> given the observed network <span class="math inline">\(A\)</span>. This is our value of interest.</li>
<li><span class="math inline">\(P(b)\)</span>: the prior probability of partition <span class="math inline">\(b\)</span>. Since observed network data is generally unique, it makes little sense to introduce information to an BSBM via the prior; the priors, thus, are derived from the observed network.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></li>
<li><span class="math inline">\(P(A|b)\)</span>: the likelihood of observing network <span class="math inline">\(A\)</span> given partition <span class="math inline">\(b\)</span>.</li>
<li><span class="math inline">\(P(A)\)</span>: the marginal probability of the observed network <span class="math inline">\(A\)</span>. Direct calculation thereof is intractable; the need for knowledge of this value is obviated via sampling.</li>
</ul>
<p>The likelihood term can be expanded further:<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p><span class="math display">\[
P(A|b)=P(A|e,b)P(e|b)
\]</span></p>
<p>where <span class="math inline">\(e\)</span> is a <span class="math inline">\(B\)</span>-by-<span class="math inline">\(B\)</span> matrix and entry <span class="math inline">\(e_{rs}\)</span> contains the number of edges shared between group <span class="math inline">\(r\)</span> and group <span class="math inline">\(s\)</span>.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>With the model specified, all that remains is to estimate the posterior probability distribution <span class="math inline">\(P(b|A)\)</span>. It should be stressed that BSBMs do not identify the single best-fitting partition (<span class="math inline">\(b\)</span>) to the exclusion of all others, but rather provide the probability of all plausible partitions.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> This is accomplished via Markov Chain Monte Carlo (MCMC) sampling, which draws samples from the joint distribution of the model and data proportional to each combination’s posterior probability <span class="citation" data-cites="peixoto2019bayesian">(<a href="#ref-peixoto2019bayesian" role="doc-biblioref">Peixoto 2019</a>)</span>. An extremely efficient MCMC algorithm for sampling from BSBMs can be found in Peixoto’s Python package <a href="https://graph-tool.skewed.de"><code>graph-tool</code></a> <span class="citation" data-cites="peixoto2014graph">(<a href="#ref-peixoto2014graph" role="doc-biblioref">Peixoto 2014b</a>)</span>.</p>
<section id="model-selection-using-minimum-description-length" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="model-selection-using-minimum-description-length"><span class="header-section-number">2.3.1</span> Model Selection using Minimum Description Length</h3>
<p>As is the case with many other unsupervised learning techniques, BSBMs require users to either pre-specify the number of non-empty blocks (<span class="math inline">\(B\)</span>) or infer the optimal number of blocks from data. Unless an appropriate number of blocks is known a priori, pre-specification of <span class="math inline">\(B\)</span> is a fraught endeavour. Setting <span class="math inline">\(B\)</span> too low paves over the nuances of the data and using a principle such as likelihood maximization imbues blockmodels with a concerning propensity for overfitting the observed network by favouring excessively large numbers of blocks <span class="citation" data-cites="peixoto2019bayesian">(<a href="#ref-peixoto2019bayesian" role="doc-biblioref">Peixoto 2019</a>)</span>.</p>
<p>Standard practice urges the use of information criteria that reward model likelihood (as a measure of overall fit) but punish model complexity to guard against overfitting. Most of the well-known and widely used criteria are not, however, applicable to SBMs. Field mainstays such as the Akiake Information Criterion (AIC) and the Bayesian Information Criterion (BIC) make invalid assumptions about SBM likelihood functions <span class="citation" data-cites="peixoto2023descriptive">(<a href="#ref-peixoto2023descriptive" role="doc-biblioref">Peixoto 2023</a>)</span>. Fortunately, Bayesian posterior probability happens to be a ‘universal code’ for an information theoretic concept known as ‘description length’ <span class="citation" data-cites="grunwald2007minimum">(<a href="#ref-grunwald2007minimum" role="doc-biblioref">Grünwald 2007</a>)</span>, which can be exploited to provide a principled choice of <span class="math inline">\(B\)</span>.</p>
<p>A model’s ‘description length’ refers to the amount of information it encodes. It can be measured using a variety of scales, the most common of which is the ‘bit’ or ‘Shannon’ <span class="citation" data-cites="shannon1948mathematical">(<a href="#ref-shannon1948mathematical" role="doc-biblioref">Shannon 1948</a>)</span>, written using capital sigma (<span class="math inline">\(\Sigma\)</span>). The concept of Occam’s Razor guides information theory towards the principle of ‘minimum description length’, which holds that models should balance providing the best possible explanation of the data with the complexity of the model used to do so.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> Peixoto’s <span class="citation" data-cites="peixoto2019bayesian">(<a href="#ref-peixoto2019bayesian" role="doc-biblioref">2019</a>)</span> derivation takes the following steps:</p>
<p>We start from the previous equation describing the BSBM’s likelihood:</p>
<p><span class="math display">\[
P(A|b)=P(A|e,b)P(e|b)
\]</span></p>
<p>Multiplying both sides by <span class="math inline">\(P(b)\)</span> gives us:</p>
<p><span class="math display">\[
P(A|b)P(b)=P(A|e,b)P(e,b)
\]</span></p>
<p>The above step places the ‘Bayes Numerator’ on the left-hand side of the equation, which trivially implies that both sides of the equation above are now proportional to the posterior probability. We can then establish a proportional relationship with description length via the bit/Shannon:</p>
<p><span class="math display">\[
P(A|e,b)P(e,b)=2^{-\Sigma}
\]</span></p>
<p>Which can be rearranged thus:</p>
<p><span class="math display">\[
log_2 P(A|e,b)P(e,b)=log_2 (2^{-\Sigma})
\]</span> <span class="math display">\[
log_2 P(A|e,b) + log_2 P(e,b) = -\Sigma log_2 (2)
\]</span> <span class="math display">\[
-log_2 P(A|e,b) - log_2 P(e,b ) = \Sigma
\]</span></p>
<p>The final expression in the above sequence highlights how MDL encodes the trade-off between model complexity and model fit: with higher values of <span class="math inline">\(B\)</span> (more blocks total), the model does a better job of retrodicting the data, which increases the likelihood (<span class="math inline">\(P(A|e,b)\)</span>), decreasing description length. As <span class="math inline">\(B\)</span> increases, however, so too does the model complexity, which increases the entropy of the priors (<span class="math inline">\(P(e,b)\)</span>), which increases description length.</p>
<p>Because the description length of a model is measured in binary bits/Shannons, it can be thought of as the number of ‘yes-or-no’ questions one would need to ask to specify and perfectly recreate the observed data in light of the model (MacKay 2003). The core idea here is that a model with a lower overall description length will have almost certainly done a better job of capturing the ‘true’ model, compared to other models with higher description lengths. In the context of BSBMs, we can think of each different choice of <span class="math inline">\(B\in{1...N}\)</span> as representing a different model; MDL provides us with a principled means of determining which model to select. The best choice of <span class="math inline">\(B\)</span>, then, is the one that produces the lowest description length of any <span class="math inline">\(B\in{1...N}\)</span>.</p>
<p>Most BSBMs can be improved by performing node reassignments via MCMC sampling. The process of reassigning nodes takes advantage of the fully-specified Bayesian probability model and its ability to provide full distributions as answers to inferential queries such as our own. Rather than provide the single most likely partition, any BSBM’s posterior can be sampled from to recover each node’s probability of belonging to each block (for a given <span class="math inline">\(B\)</span>). The end result is a distribution of nodewise block memberships, wherein each node’s probability of belonging to a given block is proportional to the likelihood of the partition that assigned the node to the block in question.</p>
<p>Finally, while the BSBM approach described above is effective at avoiding overfitting, it is still prone to underfitting: it can mistake network structure as being the product of random noise when the structure is, in fact, inferentially meaningful. The solution to this conundrum, as proposed by <span class="citation" data-cites="peixoto2019bayesian">Peixoto (<a href="#ref-peixoto2019bayesian" role="doc-biblioref">2019</a>)</span>, is to situate the node-level BSBM (which has been the focus of our chapter to this point) at the bottom rung of a potentially infinite series of hierarchical BSBM models. In essence, the solution involves modelling the blocks of a node-level BSBM as a network wherein each node represents a block, the edges between which are weighted according to the observed edge counts in the lowest-level model. This ‘network of blocks’ can itself be partitioned using a higher-level BSBM using similar logic, procedure, and model selection techniques as the node-level BSBM.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> The resulting blocks-of-blocks can themselves be modelled in yet another layer of partitioning, and so on <em>ad infinitium</em>. This layered approach to the BSMB permits the effective recovery of nested network structures without sacrificing the model’s ability to learn from data in the absence of strongly informative prior information (which would be required to recover complex structure in a single-layer BSBM). Unless otherwise noted, the Hierarchical Bayesian Stochastic Blockmodel will be our model of choice throughout the following empirical analyses.</p>
</section>
</section>
</section>
<section id="empirical-examples" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Empirical Examples</h1>
<p>In the second part of this chapter, we present two empirical examples that illustrate the use of BSBMs and speak more generally to the use of inferential approaches to network clustering. Our primary goals in this part of the chapter are to (1) illustrate some important considerations when developing a BSBM, (2) clarify what to expect in terms of results, and (3) suggest some ways of further interrogating results. To that end, we have selected two networks that differ in useful and interesting ways. The first is constructed from Enron email data, the other from data about disinformation campaigns on Twitter.</p>
<section id="the-enron-email-network" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="the-enron-email-network"><span class="header-section-number">3.1</span> The Enron Email Network</h2>
<p>Our first example uses a network derived from the ubiquitous Enron email corpus <span class="citation" data-cites="klimt2004introducing">(<a href="#ref-klimt2004introducing" role="doc-biblioref">Klimt and Yang 2004</a>)</span>, which has been used in a wide variety of research contexts, including classification, agent-based models of communication <span class="citation" data-cites="matsuyama2008analyzing vanburen2009enron">(<a href="#ref-matsuyama2008analyzing" role="doc-biblioref">Matsuyama and Terano 2008</a>; <a href="#ref-vanburen2009enron" role="doc-biblioref">VanBuren et al. 2009</a>)</span>, and social network analysis <span class="citation" data-cites="aven2015paradox corneli2019dynamic leskovec2009community">(<a href="#ref-aven2015paradox" role="doc-biblioref">Aven 2015</a>; <a href="#ref-corneli2019dynamic" role="doc-biblioref">Corneli et al. 2019</a>; <a href="#ref-leskovec2009community" role="doc-biblioref">Leskovec et al. 2009</a>)</span>.</p>
<p>The versions of the Enron email dataset available from Stanford’s SNAP database and from graph-tool’s built-in network repository are both undirected and binary <span class="citation" data-cites="leskovec2009community">(<a href="#ref-leskovec2009community" role="doc-biblioref">Leskovec et al. 2009</a>)</span>, but we consider the network to be directed and weighted. Our reasoning for this is conceptually grounded – in a corporate hierarchy, the direction and volume of email exchanges might be important. The CEO of a corporation, for example, would receive more emails from subordinates than vice versa. We include only the ‘core’ employees who were implicated in the legal proceedings and for whom complete email data and identifying information is available, forming a more-or-less complete network. For the rest of the employees, there are no records of their emails amongst each other – only to and from the core, which the Stanford SNAP database terms “sinks or sources” <span class="citation" data-cites="leskovec2009community">(<a href="#ref-leskovec2009community" role="doc-biblioref">Leskovec et al. 2009</a>)</span>. The resulting network consists of 149 nodes with 2582 edges weighted by volume of emails exchanged (total: 65,143).</p>
<p>In what follows, we use the Python package graph-tool <span class="citation" data-cites="peixoto2014graph">(<a href="#ref-peixoto2014graph" role="doc-biblioref">Peixoto 2014b</a>)</span> to develop BSBMs that partition the network into blocks that mirror the actual job titles held by employees. In other words, we will consider the job titles to be a kind of partial “ground truth” for social roles and see whether our BSBMs can approximate those roles using nothing other than the relational data. However, despite how integral this dataset is reported to be <span class="citation" data-cites="hardin2015network wilson2009discovery">(<a href="#ref-hardin2015network" role="doc-biblioref">Hardin, Sarkis, and Urc 2015</a>; <a href="#ref-wilson2009discovery" role="doc-biblioref">Wilson and Banzhaf 2009</a>)</span>, it lacks definitive metadata about the job titles of the included employees <span class="citation" data-cites="diesner2005exploration">(<a href="#ref-diesner2005exploration" role="doc-biblioref">Diesner and Carley 2005</a>)</span>. We added employee job title information to the dataset ourselves, building on a version of the dataset with other corrections made by <span class="citation" data-cites="ruhe2016enron">Ruhe (<a href="#ref-ruhe2016enron" role="doc-biblioref">2016</a>)</span>. From there, we attempted to reconcile as many available versions of the data as we could find. Where there were disagreements between many versions, or remaining vague job titles, we turned to cached online data from the Internet Archive and from Google’s web caches. Finally, we used any available LinkedIn profiles of former Enron employees to further enhance the accuracy of the position labels. We also decided to work with the raw emails in the data, rather than choosing any single version of the Enron network to trust.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a></p>
<p>Figures 1-4 show results from different BSBMs fit to the Enron email network. <a href="#fig-1" class="quarto-xref">Figure&nbsp;1</a> and <a href="#fig-2" class="quarto-xref">Figure&nbsp;2</a> are based on BSBMs that have not been refined through cycles of MCMC node reassignments. The first uses binary data whereas the second is weighted. <a href="#fig-3" class="quarto-xref">Figure&nbsp;3</a> and <a href="#fig-4" class="quarto-xref">Figure&nbsp;4</a> are refined through MCMC node reassignments. Again, the third is based on binary data and the fourth is weighted.</p>
<p>In these figures, and most others in this chapter, we can see the original complex network with circular nodes, labelled with each job title. The hierarchical BSBM is superimposed with square blue nodes, except for <a href="#fig-4" class="quarto-xref">Figure&nbsp;4</a> and <a href="#fig-5" class="quarto-xref">Figure&nbsp;5</a>, which we clustered using Traag, Waltman, and Van Eck’s <span class="citation" data-cites="traag2019louvain">(<a href="#ref-traag2019louvain" role="doc-biblioref">2019</a>)</span> Leiden algorithm rather than a BSBM for the sake of comparison. The original nodes are positioned and coloured according to their block assignments. In cases where there is more uncertainty about the block assignment, the nodes can be represented as small pie charts that give a rough sense of other plausible block assignments. High resolution colour images are available in the online supplement.</p>
<p><a href="#fig-1" class="quarto-xref">Figure&nbsp;1</a> shows results for an unweighted BSBM using only Peixoto’s <span class="citation" data-cites="peixoto2014efficient">(<a href="#ref-peixoto2014efficient" role="doc-biblioref">2014a</a>)</span> highly performative clustering heuristic. Inspecting the job titles clustered together in each block, we can identify a number of blocks that look intuitively homogenous. The CEOs are divided into different clusters, but they share a block one step up the hierarchy. Two of the three blocks in this cluster – the ones with the CEOs and COO – are primarily senior management and executives, while the third has a number of in-house lawyers and more senior management. <a href="#fig-2" class="quarto-xref">Figure&nbsp;2</a> shows results a model that uses edge weights (volume of emails) as a covariate but is otherwise identical.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> Although there is some consistency with the results in the first model, as well as a fair share of intuitive clustering, the CEO blocks are now clustered with a very large block that includes many traders.</p>
<div id="fig-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-1.png" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1"><img src="figures/Browne-Crick-McLevey-2023-Figure-1.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The Enron network with job labels, as partitioned using an unweighted BSBM.
</figcaption>
</figure>
</div>
<div id="fig-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-2.png" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2"><img src="figures/Browne-Crick-McLevey-2023-Figure-2.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The Enron network with job labels, as partitioned using a weighted BSBM.
</figcaption>
</figure>
</div>
<p><a href="#fig-3" class="quarto-xref">Figure&nbsp;3</a> and <a href="#fig-4" class="quarto-xref">Figure&nbsp;4</a> show the result of BSBMs that have been refined through a relatively modest 10,000 cycles of MCMC node reassignments, after which we assessed the minimum description length to see whether the model improved.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> The cycles of reassignment can be tracked and the frequency that a node was placed in a given block provides the marginal posterior distribution, which serves as an estimate of the probability that this was the best choice.</p>
<p>Here, ’best choice‘ is meant to imply that some latent social dynamic (i.e., not in the model) had the most influence on the observed network. A purely hypothetical explanation might be that certain administrative assistants act as proxies for the CEOs they were grouped with, sending some portion of the emails that the CEOs would have otherwise sent. This could just as easily be driven by social steering of staff barbecue plans as it is by work-related emails. It could also be something as complex as deliberate instruction, meant to make operations appear “business-as-usual” despite the fraudulent activity happening behind the scenes.</p>
<p>In the refined unweighted SBM shown in <a href="#fig-3" class="quarto-xref">Figure&nbsp;3</a>, there are some significant changes that stand out. The two blocks of CEOs and executive management are now clustered together in the hierarchy, with the other executive block now joining a block of primarily non-executive employees. Changes in the refined weighted SBM are less visibly apparent but there is a great deal of information available here for further comparison.</p>
<div id="fig-3" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-3.png" class="lightbox" data-glightbox="description: .lightbox-desc-3" data-gallery="quarto-lightbox-gallery-3"><img src="figures/Browne-Crick-McLevey-2023-Figure-3.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: The Enron network with job labels, as partitioned using an unweighted BSBM, refined through MCMC.
</figcaption>
</figure>
</div>
<div id="fig-4" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-4.png" class="lightbox" data-glightbox="description: .lightbox-desc-4" data-gallery="quarto-lightbox-gallery-4"><img src="figures/Browne-Crick-McLevey-2023-Figure-4.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: The Enron network with job labels, as partitioned using a weighted BSBM, refined through MCMC.
</figcaption>
</figure>
</div>
<p>As mentioned previously, we should not be too certain about block assignments where nodes are colored by pie charts, which indicate the plausibility of some other block assignment. One example is the director on the right side of the unweighted network (see <a href="#fig-2" class="quarto-xref">Figure&nbsp;2</a>), who was placed alone in a block, but with the possibility of being assigned to either of the two blocks below. Multiple plausible block assignments like this could mean that an employee has a diverse set of behaviours in the company, that the model or data do a poor job of representing their behaviours, or that more than one model is needed to infer the particular social dynamic where they are more consistent.</p>
<p><span class="citation" data-cites="peixoto2021revealing">Peixoto (<a href="#ref-peixoto2021revealing" role="doc-biblioref">2021</a>)</span> has recently implemented a model clustering function in graph-tool that can help researchers get a sense of whether there are different generative stories consistent with the data. For each cluster of models, an overall likelihood contribution to the data can be calculated as a proportion to the other models, out of 100. In the case of the Enron models, only two clusters ever turn up and the second with less than 0.001 likelihood, so is not worth exploring here. The uncertainty of some of the individual node assignments, often seen in directors and managers, would be a better place to look.</p>
<p>For the sake of comparison, we provide unweighted and weighted assortative cluster results from the Leiden algorithm, using the respective network layouts from the refined SBM models. The results are shown in <a href="#fig-5" class="quarto-xref">Figure&nbsp;5</a> and <a href="#fig-6" class="quarto-xref">Figure&nbsp;6</a>, and in <a href="#tbl-mdl" class="quarto-xref">Table&nbsp;1</a> and <a href="#tbl-rmi" class="quarto-xref">Table&nbsp;2</a>. In both cases, the Leiden algorithm was run with the additional refinement iterations that ensure modularity has been maximized to full model resolution <span class="citation" data-cites="traag2019louvain">(<a href="#ref-traag2019louvain" role="doc-biblioref">Traag, Waltman, and Van Eck 2019</a>)</span>.</p>
<div id="fig-5" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-5.png" class="lightbox" data-glightbox="description: .lightbox-desc-5" data-gallery="quarto-lightbox-gallery-5"><img src="figures/Browne-Crick-McLevey-2023-Figure-5.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: The Enron network with job labels, as partitioned using an unweighted Leiden algorithm.
</figcaption>
</figure>
</div>
<div id="fig-6" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-6.png" class="lightbox" data-glightbox="description: .lightbox-desc-6" data-gallery="quarto-lightbox-gallery-6"><img src="figures/Browne-Crick-McLevey-2023-Figure-6.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: The Enron network with job labels, as partitioned using a weighted Leiden algorithm.
</figcaption>
</figure>
</div>
<p><a href="#tbl-mdl" class="quarto-xref">Table&nbsp;1</a> compares the MDL (i.e., how successfully the model has condensed the information required to recreate the network) for the six analyses so far (4 partitioned with BSBMs, 2 with Leiden). We can see that the three models with edge weights have significantly longer description lengths. This is to be expected because MDL compares different ways of modeling the same data. As soon as edge weights or other covariates are added to the network, the data used to represent with the model has increased. MDL cannot indicate whether the weighted or unweighted model is preferable. However, for both weighted and unweighted networks, we can see that the SBMs we refined with 10,000 MCMC runs both slightly outperform the unrefined SBMs, and moderately outperform the Leiden algorithm.</p>
<div id="tbl-mdl" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-mdl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Minimum Description Length (MDL) comparison for the six Enron analyses.
</figcaption>
<div aria-describedby="tbl-mdl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">BSBM</th>
<th style="text-align: left;">BSBM, refined with MCMC</th>
<th style="text-align: left;">Leiden</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">unweighted</td>
<td style="text-align: left;">6350.47</td>
<td style="text-align: left;">6336.73</td>
<td style="text-align: left;">6660.11</td>
</tr>
<tr class="even">
<td style="text-align: left;">weighted</td>
<td style="text-align: left;">16763.89</td>
<td style="text-align: left;">16754.96</td>
<td style="text-align: left;">16941.6</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>We can also evaluate our models using another metric from information theory – mutual information. Mutual information is widely used to evaluate cluster and classification models by comparing the consensus between a ground-truth label of datapoints and the labels produced by a model. There have been a number of variants of mutual information introduced to improve on different aspects of the measure, often for different applications. Here, we use Newman, Cantwell, and Young’s <span class="citation" data-cites="newman2020improved">(<a href="#ref-newman2020improved" role="doc-biblioref">2020</a>)</span> reduced mutual information (RMI) score, which was developed with particular attention to evaluating community detection methods in networks. We can use RMI to calculate the agreement between any clustering – “ground-truth” or not. Our focus, however, will be on how each model performs relative to the ‘Job Title’ classifications we added to the dataset.</p>
<p><a href="#tbl-rmi" class="quarto-xref">Table&nbsp;2</a> shows the RMI scores of pairwise comparisons between the six model examples above and the employee job titles, with a score of 1 indicating perfect agreement. Contrary to the MDL measure, the unrefined variants of the SBM perform better here than the refined ones, with the weighted unrefined SBM score doubling the second-best score of the weighted Leiden algorithm.</p>
<div id="tbl-rmi" class="quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-rmi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Reduced mutual information (RMI) scores for pairwise comparisons of the six Enron analyses and the employees official job titles.
</figcaption>
<div aria-describedby="tbl-rmi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Job Title</th>
<th style="text-align: left;">SBM unweighted</th>
<th style="text-align: left;">SBM weighted</th>
<th style="text-align: left;">SBM refined unweighted</th>
<th style="text-align: left;">SBM refined weighted</th>
<th style="text-align: left;">Leiden unweighted</th>
<th style="text-align: left;">Leiden weighted</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Job Title</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SBM unweighted</td>
<td style="text-align: left;">0.004363</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">SBM weighted</td>
<td style="text-align: left;">0.042249</td>
<td style="text-align: left;">0.557893</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">SBM refined unweighted</td>
<td style="text-align: left;">-0.01196</td>
<td style="text-align: left;">0.866441</td>
<td style="text-align: left;">0.54449 1</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">SBM refined weighted</td>
<td style="text-align: left;">0.01394</td>
<td style="text-align: left;">0.484362</td>
<td style="text-align: left;">0.74883</td>
<td style="text-align: left;">0.482392</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Leiden unweighted</td>
<td style="text-align: left;">-0.00021</td>
<td style="text-align: left;">0.61373</td>
<td style="text-align: left;">0.547643</td>
<td style="text-align: left;">0.595718</td>
<td style="text-align: left;">0.465708</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Leiden weighted</td>
<td style="text-align: left;">0.020552</td>
<td style="text-align: left;">0.4696</td>
<td style="text-align: left;">0.534218</td>
<td style="text-align: left;">0.478979</td>
<td style="text-align: left;">0.437218</td>
<td style="text-align: left;">0.56049</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>What explains the apparent contradiction between MDL and RMI? Overfitting is a likely explanation: recall the results of the unrefined weighted SBM (<a href="#fig-2" class="quarto-xref">Figure&nbsp;2</a>), where the two executive blocks were clustered with a higher-order block containing many traders. Traders are the most common employee label (there are 35 of them), so placing them together in clusters will disproportionately impact a mutual information score. In this case, the RMI score is 0.44 when placing all of the traders in one group when every other employee is in a second group. In this sense, models that cluster the most common label (‘Trader’, in this case) together will score well on RMI whilst not necessarily featuring a comparatively laudable MDL score.</p>
<p>The conceptual caveats here are multiple. We rarely have a “ground truth” available, but it is also worth stressing the fact that the job titles in this example are only one part of the “ground truth” – or are, perhaps, a product of a more general “ground truth” that jointly gives rise to the observed network structure and the job titles. Various norms of corporate hierarchical structure – such as proscribed efficiency guidelines, proximity, and social taboos – are also likely to have been influential. Without more information, the only sure inference to make here is that workplace roles have had some form of influence on who sent emails to whom.</p>
</section>
<section id="disinformation-on-twitter-ira-tweets" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="disinformation-on-twitter-ira-tweets"><span class="header-section-number">3.2</span> Disinformation on Twitter: IRA Tweets</h2>
<p>In our second empirical example, we analyze networks derived from a corpus of Tweets that Twitter determined were the work of Russia’s Internet Research Agency (IRA) as part of their election interference research initiative.<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> In 2018, Twitter began releasing datasets of activity by accounts that they had identified as state-backed operations <span class="citation" data-cites="roeder3we">(<a href="#ref-roeder3we" role="doc-biblioref">Roeder, n.d.</a>)</span>. Data attributed to Russia’s infamous Internet Research Agency (IRA) was the centerpiece of these releases, containing information on roughly 10 million tweets from 4,611 accounts.</p>
<p>There are two distinct approaches to forming network edges from Twitter: using metadata (e.g.&nbsp;followers and followees) and using activity data (e.g.&nbsp;mentions, retweets, or replies). In this case, we aggregated all three forms of activity data. Since the full IRA network is too large and complex to give a proper treatment in this brief example, we filter the network to retain only the 1,000 most heavily weighted edges. This leaves 777 nodes in the network, with 555 identified as affiliated with the IRA and 222 accounts not identified as affiliated with the IRA. The combined weight of these 1,000 edges is 423,911 – so, a lot of activity. This network represents the source and target accounts involved in the heaviest amount of Twitter interaction surrounding the IRA actors. Notably, the data only includes Tweets made by the IRA accounts, forming a directed network that can still be blockmodeled.</p>
<p>Unlike the Enron data, we know next-to-nothing about the identity of the individuals responsible – it is likely that each IRA worker was responsible for many such accounts. Insofar as Twitter’s undisclosed method for detecting state actors can be trusted as accurate, we do know that the Twitter accounts in question were acting under the guidance of some authority. It is also reasonable to assume that the behavior of these accounts is much more singularly focused than that of corporate employees; if a state-employed Twitter operative wanted to plan a barbeque with their co-workers, they would do it somewhere other than in public Tweets from their ‘sock puppet’ accounts. Given what we know about the generative processes giving rise to this network, one place to start might be to look for evidence of any coordination at all.</p>
<p>In the four subplots of <a href="#fig-7" class="quarto-xref">Figure&nbsp;7</a>, we show the top 1,000 edges from the IRA network at a few key time points from a day-by-day tie formation animation. These edges are displayed in the animation when first established, so although they eventually have the largest edge weights, they are drawn on the day when the edge weight was 1 or more. Source nodes are circled in black if they first interacted with their target on the day of the image. Similarly, in the online color versions of these figures, the IRA accounts are shown in red, non-IRA in blue, and deleted accounts in orange. Edges directed to each of those account categories are coloured in the same scheme.</p>
<div id="fig-7" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-7" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ira1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ira1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-7-Subplot-A.png" class="lightbox" data-glightbox="description: .lightbox-desc-7" data-gallery="fig-7"><img src="figures/Browne-Crick-McLevey-2023-Figure-7-Subplot-A.png" id="fig-ira1" class="img-fluid figure-img" data-ref-parent="fig-7"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ira1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-7" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ira2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ira2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-8-Subplot-B.png" class="lightbox" data-glightbox="description: .lightbox-desc-8" data-gallery="fig-7"><img src="figures/Browne-Crick-McLevey-2023-Figure-8-Subplot-B.png" id="fig-ira2" class="img-fluid figure-img" data-ref-parent="fig-7"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ira2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-7" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ira3" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ira3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-7-Subplot-C.png" class="lightbox" data-glightbox="description: .lightbox-desc-9" data-gallery="fig-7"><img src="figures/Browne-Crick-McLevey-2023-Figure-7-Subplot-C.png" id="fig-ira3" class="img-fluid figure-img" data-ref-parent="fig-7"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ira3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c)
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-7" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-ira3" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ira3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-7-Subplot-D.png" class="lightbox" data-glightbox="description: .lightbox-desc-10" data-gallery="fig-7"><img src="figures/Browne-Crick-McLevey-2023-Figure-7-Subplot-D.png" id="fig-ira3" class="img-fluid figure-img" data-ref-parent="fig-7"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ira3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Activity in the IRA network at four points in time. Subplots B-D show December 12th, 20th, and 21st of 2015, respectively. Subplot A shows the network on September 7th, 2017, when the last IRA Tweet in the dataset was sent.
</figcaption>
</figure>
</div>
<p>Subplot A in <a href="#fig-7" class="quarto-xref">Figure&nbsp;7</a> shows the network on September 7th, 2017, when the last IRA Tweet in the dataset was sent. The large swath of edges from the bottom occurred primarily in the span of two days. They all originated from the same block of IRA accounts, and they all targeted the same account, rianru, which is the account of state-owned Russian news agency RIA Novosti. It would be reasonable to say here that there is evidence of some form of coordinated action. The other blocks display less dramatic but still distinguishable patterns.</p>
<p>The IRA Twitter blockmodel might suggest the presence of marked distinctions between different sets of behaviours, each guided by sets of strategies from senior decision makers. On the other hand, there is no way to analyze the available data to distinguish between five distinct blocks of Twitter accounts, each belonging to sets of state employees with official orders and, for example, five state employees each running multiple accounts as they see fit – in other words, we can’t easily distinguish top-down coordination from simultaneous autonomous activity. Likewise, the media focus that surrounded online state-backed behaviour during the US election cycle might make it tempting, and legitimately compelling, to conclude that any identified organized behaviour is supportive evidence of foreign influence operations. This conclusion is exactly what Twitter suggested when releasing the data. In reality, disinformation researchers increasingly find that a large portion of online disinformation is targeted domestically <span class="citation" data-cites="grace2022disinfo somerville2020disinformation">(<a href="#ref-grace2022disinfo" role="doc-biblioref">Grace 2022</a>; <a href="#ref-somerville2020disinformation" role="doc-biblioref">Somerville and Heerin 2020</a>)</span>.</p>
<div id="fig-8" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-8" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-ira1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ira1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-8-Subplot-A.png" class="lightbox" data-glightbox="description: .lightbox-desc-11" data-gallery="fig-8"><img src="figures/Browne-Crick-McLevey-2023-Figure-8-Subplot-A.png" id="fig-ira1" class="img-fluid figure-img" style="width:40.0%" data-ref-parent="fig-8"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ira1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-8" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-ira2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ira2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-8-Subplot-B.png" class="lightbox" data-glightbox="description: .lightbox-desc-12" data-gallery="fig-8"><img src="figures/Browne-Crick-McLevey-2023-Figure-8-Subplot-B.png" id="fig-ira2" class="img-fluid figure-img" style="width:40.0%" data-ref-parent="fig-8"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ira2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-8" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-ira3" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-ira3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="figures/Browne-Crick-McLevey-2023-Figure-8-Subplot-C.png" class="lightbox" data-glightbox="description: .lightbox-desc-13" data-gallery="fig-8"><img src="figures/Browne-Crick-McLevey-2023-Figure-8-Subplot-C.png" id="fig-ira3" class="img-fluid figure-img" style="width:40.0%" data-ref-parent="fig-8"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-ira3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Three different enlarged views of the filtered IRA Network.
</figcaption>
</figure>
</div>
<p>The network visualizations in <a href="#fig-8" class="quarto-xref">Figure&nbsp;8</a> show an enlarged view of some key distinct patterns in the network. Subplot A shows a small number of IRA accounts targeting Twitter accounts of non-descript origin, and primarily spreading conspiracy theories of the time.<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> The second image shows activity focused on popular US media organizations, like <em>Mashable</em>, <em>The Washington Post</em>, and <em>Fox News</em>. In the third image is a mix, with <em>Al Jazeera</em>, the <em>Financial Times</em>, and a popular Russia-based satire account as targets. There is a great deal of in-depth analysis that could be undertaken here, but it does seem evident that the activity of these accounts was not solely focused on the US election, especially given the attention paid to <em>RIA Novosti</em> (<em>rianru</em>).</p>
<p>Inference about the goals behind these Twitter strategies might be possible, but not without care – how would a foreign influence objective be distinguishable from purposefully crafting the <em>impression</em> of foreign influence, for other purposes? And how would the intended audience be identified? When 100 accounts send 10,000 Tweets each at the <em>New York Times</em>, they are almost certainly not banking on the producers of that newspaper to consider their statements. In still other settings, it turns out that none of these considerations even matter, where the reality is that bots are just tweeting amongst each other <span class="citation" data-cites="thread2021bots">(<a href="#ref-thread2021bots" role="doc-biblioref">Thread 2021</a>)</span>.</p>
<p>As the two foregoing analyses have made abundantly clear, BSBMs are powerful tools for drawing inferences about the processes that give rise to social structure in networks. What should be equally clear, however, is that researchers must exercise caution when interpreting said inferences. In our analysis of the Enron email network, we saw that BSBMs admirably retrodict some of the structures we might expect to see in a hierarchical network of corporate communications, but were equally made aware of the fact that BSBMs do not necessarily measure any particular kind of ‘ground truth’ – or if they do, that it may not be the same ground truth researchers expect to draw inferences about. As <span class="citation" data-cites="white1976social">H. White, Boorman, and Breiger (<a href="#ref-white1976social" role="doc-biblioref">1976</a>)</span>, <span class="citation" data-cites="robins2011exponential">Robins (<a href="#ref-robins2011exponential" role="doc-biblioref">2011</a>)</span>; and <span class="citation" data-cites="nadel2013theory">Nadel (<a href="#ref-nadel2013theory" role="doc-biblioref">[1957] 2013</a>)</span> are wont to emphasize: social roles are complex, embedded, and multifaceted: researchers cannot hope to apprehend the totality of a social role through the analysis of one kind of social tie. In our analysis of the IRA disinformation campaign on Twitter, we encountered the pitfalls of ascribing a causal story to the patterns of behaviour hinted at by the results of a BSBM: the same results can be easily re-interpreted to support conclusions that emphasize the foreign influence role of IRA activity, the domestic influence role of IRA activity, or the seemingly impotent bot-on-bot IRA activity.</p>
</section>
</section>
<section id="conclusion" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Conclusion</h1>
<p>In this chapter, we introduced readers to the Bayesian Stochastic Blockmodel – which is a powerful inferential counterpart to prevailing descriptive approaches to community detection and network clustering – and demonstrated the process of applying and interpreting BSBMs in two very different contexts. As with all unsupervised learning, great care is required when specifying and drawing inferences from the graph partitions we obtain by developing and fitting BSBMs. This is not because SBMs are uniquely prone to misapplication or are otherwise unwieldy. BSBMs open many exciting research opportunities for network scientists by combining decades of insightful work on equivalence, blockmodels, and network clustering (see Dorien, this volume) with probabilistic thinking and generative modelling. But, as with all other approaches, we need careful and deliberate analysis to make inferences about meaningful human behaviour.</p>
</section>
<section id="references" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> References</h1>
<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">Figure&nbsp;1: The Enron network with job labels, as partitioned using an unweighted BSBM.</span>
<span class="glightbox-desc lightbox-desc-2">Figure&nbsp;2: The Enron network with job labels, as partitioned using a weighted BSBM.</span>
<span class="glightbox-desc lightbox-desc-3">Figure&nbsp;3: The Enron network with job labels, as partitioned using an unweighted BSBM, refined through MCMC.</span>
<span class="glightbox-desc lightbox-desc-4">Figure&nbsp;4: The Enron network with job labels, as partitioned using a weighted BSBM, refined through MCMC.</span>
<span class="glightbox-desc lightbox-desc-5">Figure&nbsp;5: The Enron network with job labels, as partitioned using an unweighted Leiden algorithm.</span>
<span class="glightbox-desc lightbox-desc-6">Figure&nbsp;6: The Enron network with job labels, as partitioned using a weighted Leiden algorithm.</span>
<span class="glightbox-desc lightbox-desc-7">Figure&nbsp;7&nbsp;(a): </span>
<span class="glightbox-desc lightbox-desc-8">Figure&nbsp;7&nbsp;(b): </span>
<span class="glightbox-desc lightbox-desc-9">Figure&nbsp;7&nbsp;(c): </span>
<span class="glightbox-desc lightbox-desc-10">Figure&nbsp;7&nbsp;(d): </span>
<span class="glightbox-desc lightbox-desc-11">Figure&nbsp;8&nbsp;(a): </span>
<span class="glightbox-desc lightbox-desc-12">Figure&nbsp;8&nbsp;(b): </span>
<span class="glightbox-desc lightbox-desc-13">Figure&nbsp;8&nbsp;(c): </span>
</div>

</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-anderson1992building" class="csl-entry" role="listitem">
Anderson, Carolyn, Stanley Wasserman, and Katherine Faust. 1992. <span>“Building Stochastic Blockmodels.”</span> <em>Social Networks</em> 14 (1-2): 137–61.
</div>
<div id="ref-arabie1982blockmodels" class="csl-entry" role="listitem">
Arabie, Phipps, Scott A Boorman, et al. 1982. <span>“Blockmodels: Developments and Prospects.”</span> In <em>Classifying Social Data: New Applications of Analytic Methods for Social Science Research</em>, edited by Herschel C. Hudson, 177–98. Jossey-Bass San Francisco.
</div>
<div id="ref-arabie1978constructing" class="csl-entry" role="listitem">
Arabie, Phipps, Scott A Boorman, and Paul Levitt. 1978. <span>“Constructing Blockmodels: How and Why.”</span> <em>Journal of Mathematical Psychology</em> 17 (1): 21–63.
</div>
<div id="ref-aven2015paradox" class="csl-entry" role="listitem">
Aven, Brandy. 2015. <span>“The Paradox of Corrupt Networks: An Analysis of Organizational Crime at Enron.”</span> <em>Organization Science</em> 26 (4): 980–96.
</div>
<div id="ref-blondel2008fast" class="csl-entry" role="listitem">
Blondel, Vincent, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008. <span>“Fast Unfolding of Communities in Large Networks.”</span> <em>Journal of Statistical Mechanics: Theory and Experiment</em> 2008 (10): P10008.
</div>
<div id="ref-boorman1976social" class="csl-entry" role="listitem">
Boorman, Scott A, and Harrison White. 1976. <span>“Social Structure from Multiple Networks. II. Role Structures.”</span> <em>American Journal of Sociology</em> 81 (6): 1384–1446.
</div>
<div id="ref-breiger1975algorithm" class="csl-entry" role="listitem">
Breiger, Ronald, Scott A Boorman, and Phipps Arabie. 1975. <span>“An Algorithm for Clustering Relational Data with Applications to Social Network Analysis and Comparison with Multidimensional Scaling.”</span> <em>Journal of Mathematical Psychology</em> 12 (3): 328–83.
</div>
<div id="ref-clayton2021bernoulli" class="csl-entry" role="listitem">
Clayton, Aubrey. 2021. <em>Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science</em>. New York: Columbia University Press.
</div>
<div id="ref-collins1988theoretical" class="csl-entry" role="listitem">
Collins, Randall. 1988. <em>Theoretical Sociology</em>. San Francisco: Harcourt Brace Jovanovich.
</div>
<div id="ref-corneli2019dynamic" class="csl-entry" role="listitem">
Corneli, Marco, Charles Bouveyron, Pierre Latouche, and Fabrice Rossi. 2019. <span>“The Dynamic Stochastic Topic Block Model for Dynamic Networks with Textual Edges.”</span> <em>Statistics and Computing</em> 29: 677–95.
</div>
<div id="ref-cox1946probability" class="csl-entry" role="listitem">
Cox, Richard. 1946. <span>“Probability, Frequency and Reasonable Expectation.”</span> <em>American Journal of Physics</em> 14 (1): 1–13.
</div>
<div id="ref-diesner2005exploration" class="csl-entry" role="listitem">
Diesner, Jana, and Kathleen Carley. 2005. <span>“Exploration of Communication Networks from the Enron Email Corpus.”</span> In <em>SIAM International Conference on Data Mining: Workshop on Link Analysis, Counterterrorism and Security, Newport Beach, CA</em>, 3–14.
</div>
<div id="ref-dorien2023shsna3bpr" class="csl-entry" role="listitem">
Dorien, Patrick, Anuška Ferligoj, and Vladimir Batagelj. 2024. <span>“Blockmodelling, Positions, and Roles.”</span> In <em>The SAGE Handbook of Social Network Analysis (Volume 2)</em>, edited by John McLevey, John Scott, and Peter J Carrington, 404–16. London: SAGE.
</div>
<div id="ref-Erdos1959pmd" class="csl-entry" role="listitem">
Erdös, P, and A Rényi. 1959. <span>“On Random Graphs i.”</span> <em>Publicationes Mathematicae Debrecen</em> 6: 290–97.
</div>
<div id="ref-erickson1988relational" class="csl-entry" role="listitem">
Erickson, Bonnie. 1988. <span>“The Relational Basis of Attitudes.”</span> In <em>Social Structures: A Network Approach</em>, edited by Barry Wellman and Stephen Berkowitz. Cambridge: Cambridge University Press.
</div>
<div id="ref-festinger1949analysis" class="csl-entry" role="listitem">
Festinger, Leon. 1949. <span>“The Analysis of Sociograms Using Matrix Algebra.”</span> <em>Human Relations</em> 2 (2): 153–58.
</div>
<div id="ref-friedkin1984structural" class="csl-entry" role="listitem">
Friedkin, Noah. 1984. <span>“Structural Cohesion and Equivalence Explanations of Social Homogeneity.”</span> <em>Sociological Methods &amp; Research</em> 12 (3): 235–61.
</div>
<div id="ref-grace2022disinfo" class="csl-entry" role="listitem">
Grace, Perri. 2022. <span>“Inside Russia’s Domestic Disinformation Ecosystem.”</span> Inkstick. <a href="https://inkstickmedia.com/inside-russias-domestic-disinformation-ecosystem/">https://inkstickmedia.com/inside-russias-domestic-disinformation-ecosystem/</a>.
</div>
<div id="ref-grunwald2007minimum" class="csl-entry" role="listitem">
Grünwald, Peter D. 2007. <em>The Minimum Description Length Principle</em>. MIT press.
</div>
<div id="ref-hardin2015network" class="csl-entry" role="listitem">
Hardin, JS, Ghassan Sarkis, and PC Urc. 2015. <span>“Network Analysis with the Enron Email Corpus.”</span> <em>Journal of Statistics Education</em> 23 (2).
</div>
<div id="ref-holland1983stochastic" class="csl-entry" role="listitem">
Holland, Paul, Kathryn Blackmond Laskey, and Samuel Leinhardt. 1983. <span>“Stochastic Blockmodels: First Steps.”</span> <em>Social Networks</em> 5 (2): 109–37.
</div>
<div id="ref-jaynes2003probability" class="csl-entry" role="listitem">
Jaynes, Edwin. 2003. <em>Probability Theory: The Logic of Science</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-klimt2004introducing" class="csl-entry" role="listitem">
Klimt, Bryan, and Yiming Yang. 2004. <span>“Introducing the Enron Corpus.”</span> In <em>CEAS</em>, 45:92–96.
</div>
<div id="ref-leskovec2009community" class="csl-entry" role="listitem">
Leskovec, Jure, Kevin Lang, Anirban Dasgupta, and Michael Mahoney. 2009. <span>“Community Structure in Large Networks: Natural Cluster Sizes and the Absence of Large Well-Defined Clusters.”</span> <em>Internet Mathematics</em> 6 (1): 29–123.
</div>
<div id="ref-light1979primer" class="csl-entry" role="listitem">
Light, John, and Nicholas Mullins. 1979. <span>“A Primer on Blockmodeling Procedure.”</span> In <em>Perspectives on Social Network Research</em>, edited by Paul Holland and Samuel Leinhardt, 85–118. New York: Academic Press.
</div>
<div id="ref-lorrain1971structural" class="csl-entry" role="listitem">
Lorrain, Francois, and Harrison White. 1971. <span>“Structural Equivalence of Individuals in Social Networks.”</span> <em>The Journal of Mathematical Sociology</em> 1 (1): 49–80.
</div>
<div id="ref-luce1949method" class="csl-entry" role="listitem">
Luce, Duncan, and Albert Perry. 1949. <span>“A Method of Matrix Analysis of Group Structure.”</span> <em>Psychometrika</em> 14 (2): 95–116.
</div>
<div id="ref-matsuyama2008analyzing" class="csl-entry" role="listitem">
Matsuyama, Shinako, and Takao Terano. 2008. <span>“Analyzing the ENRON Communication Network Using Agent-Based Simulation.”</span> <em>Journal of Networks</em> 3 (7): 26–33.
</div>
<div id="ref-mcelreath2020statistical" class="csl-entry" role="listitem">
McElreath, Richard. 2020. <em>Statistical Rethinking: A Bayesian Course with Examples in <span>R</span> and STAN</em>. New York: Chapman; Hall/CRC.
</div>
<div id="ref-moody2023shsna2cohesion" class="csl-entry" role="listitem">
Moody, James, and Peter J Mucha. 2024. <span>“Structural Cohesion and Cohesive Subgroups.”</span> In <em>The SAGE Handbook of Social Network Analysis (Volume 2)</em>, edited by John McLevey, John Scott, and Peter J Carrington, 376–91. London: SAGE.
</div>
<div id="ref-nadel2013theory" class="csl-entry" role="listitem">
Nadel, Siegfried Frederick. (1957) 2013. <em>The Theory of Social Structure</em>. Vol. 8. Routledge.
</div>
<div id="ref-newman2020improved" class="csl-entry" role="listitem">
Newman, Mark, George Cantwell, and Jean-Gabriel Young. 2020. <span>“Improved Mutual Information Measure for Clustering, Classification, and Community Detection.”</span> <em>Physical Review E</em> 101 (4): 042304.
</div>
<div id="ref-nowicki2001estimation" class="csl-entry" role="listitem">
Nowicki, Krzysztof, and Tom AB Snijders. 2001. <span>“Estimation and Prediction for Stochastic Blockstructures.”</span> <em>Journal of the American Statistical Association</em> 96 (455): 1077–87.
</div>
<div id="ref-peixoto2014efficient" class="csl-entry" role="listitem">
Peixoto, Tiago. 2014a. <span>“Efficient Monte Carlo and Greedy Heuristic for the Inference of Stochastic Block Models.”</span> <em>Physical Review E</em> 89 (1): 012804.
</div>
<div id="ref-peixoto2014graph" class="csl-entry" role="listitem">
———. 2014b. <span>“The Graph-Tool Python Library.”</span> <em>Figshare</em>. <a href="https://doi.org/10.6084/m9.figshare.1164194">https://doi.org/10.6084/m9.figshare.1164194</a>.
</div>
<div id="ref-peixoto2019bayesian" class="csl-entry" role="listitem">
———. 2019. <span>“Bayesian Stochastic Blockmodeling.”</span> In <em>Advances in Network Clustering and Blockmodeling</em>, edited by Patrick Doreian, Vladimir Batagelj, and Anuska Ferligoj, 289–332. Oxford: John Wiley &amp; Sons.
</div>
<div id="ref-peixoto2021revealing" class="csl-entry" role="listitem">
———. 2021. <span>“Revealing Consensus and Dissensus Between Network Partitions.”</span> <em>Physical Review X</em> 11 (2): 021003.
</div>
<div id="ref-peixoto2023descriptive" class="csl-entry" role="listitem">
———. 2023. <span>“Descriptive Vs. Inferential Community Detection in Networks: Pitfalls, Myths and Half-Truths.”</span> <em>Elements in the Structure and Dynamics of Complex Networks</em>.
</div>
<div id="ref-robins2011exponential" class="csl-entry" role="listitem">
Robins, Garry. 2011. <span>“Exponential Random Graph Models for Social Networks.”</span> In <em>The SAGE Handbook of Social Network Analysis</em>, edited by John Scott and Peter J Carrington, 484–500. London: Sage.
</div>
<div id="ref-roeder3we" class="csl-entry" role="listitem">
Roeder, Oliver. n.d. <span>“We Gave You 3 Million Russian Troll Tweets. Here’s What You’ve Found so Far, 2018.”</span> FiveThirtyEight. <a href="https://fivethirtyeight.com/features/what-we-found-in-3-million-russian-troll-tweets/">https://fivethirtyeight.com/features/what-we-found-in-3-million-russian-troll-tweets/</a>.
</div>
<div id="ref-ruhe2016enron" class="csl-entry" role="listitem">
Ruhe, Arne Hendrik. 2016. <span>“Enron Data.”</span> www.ahschulz.de/enron-email-data/.
</div>
<div id="ref-mclevey2023shsna1intro" class="csl-entry" role="listitem">
Scott, John, John McLevey, and Peter J Carrington. 2024. <span>“Introduction.”</span> In <em>The SAGE Handbook of Social Network Analysis (Volume 2)</em>, edited by John McLevey, John Scott, and Peter J Carrington, 1–18. London: SAGE.
</div>
<div id="ref-shannon1948mathematical" class="csl-entry" role="listitem">
Shannon, Claude. 1948. <span>“A Mathematical Theory of Communication.”</span> <em>The Bell System Technical Journal</em> 27 (3): 379–423.
</div>
<div id="ref-snijders1997estimation" class="csl-entry" role="listitem">
Snijders, Tom AB, and Krzysztof Nowicki. 1997. <span>“Estimation and Prediction for Stochastic Blockmodels for Graphs with Latent Block Structure.”</span> <em>Journal of Classification</em> 14 (1): 75–100.
</div>
<div id="ref-somerville2020disinformation" class="csl-entry" role="listitem">
Somerville, Alistair, and Jonas Heerin. 2020. <span>“The Disinformation Shift: From Foreign to Domestic.”</span> <em>Georgetown Journal of International Affairs</em>.
</div>
<div id="ref-thread2021bots" class="csl-entry" role="listitem">
Thread, Common. 2021. <span>“Four Truths about Bots.”</span> Twitter. <a href="https://blog.twitter.com/common-thread/en/topics/stories/2021/four-truths-about-bots">https://blog.twitter.com/common-thread/en/topics/stories/2021/four-truths-about-bots</a>.
</div>
<div id="ref-traag2019louvain" class="csl-entry" role="listitem">
Traag, Vincent, Ludo Waltman, and Nees Jan Van Eck. 2019. <span>“From Louvain to Leiden: Guaranteeing Well-Connected Communities.”</span> <em>Scientific Reports</em> 9 (1): 5233.
</div>
<div id="ref-vanburen2009enron" class="csl-entry" role="listitem">
VanBuren, Victoria, David Villarreal, Thomas McMillen, and Andrew Minnicks. 2009. <span>“Enron Dataset Research: E-Mail Relevance Classification.”</span>
</div>
<div id="ref-wang1987stochastic" class="csl-entry" role="listitem">
Wang, Yuchung, and George Wong. 1987. <span>“Stochastic Blockmodels for Directed Graphs.”</span> <em>Journal of the American Statistical Association</em> 82 (397): 8–19.
</div>
<div id="ref-wasserman1987stochastic" class="csl-entry" role="listitem">
Wasserman, Stanley, and Carolyn Anderson. 1987. <span>“Stochastic a Posteriori Blockmodels: Construction and Assessment.”</span> <em>Social Networks</em> 9 (1): 1–36.
</div>
<div id="ref-stanley1994social" class="csl-entry" role="listitem">
Wasserman, Stanley, and Katherine Faust. 1994. <em>Social Network Analysis: Methods and Applications</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-white1983graph" class="csl-entry" role="listitem">
White, Douglas, and Karl Reitz. 1983. <span>“Graph and Semigroup Homomorphisms on Networks of Relations.”</span> <em>Social Networks</em> 5 (2): 193–234.
</div>
<div id="ref-white1976social" class="csl-entry" role="listitem">
White, Harrison, Scott A Boorman, and Ronald Breiger. 1976. <span>“Social Structure from Multiple Networks. I. Blockmodels of Roles and Positions.”</span> <em>American Journal of Sociology</em> 81 (4): 730–80.
</div>
<div id="ref-wilson2009discovery" class="csl-entry" role="listitem">
Wilson, Garnett, and Wolfgang Banzhaf. 2009. <span>“Discovery of Email Communication Networks from the Enron Corpus with a Genetic Algorithm Using Social Network Analysis.”</span> In <em>2009 IEEE Congress on Evolutionary Computation</em>, 3256–63. IEEE.
</div>
<div id="ref-zhang2020statistical" class="csl-entry" role="listitem">
Zhang, Lizhi, and Tiago Peixoto. 2020. <span>“Statistical Inference of Assortative Community Structures.”</span> <em>Physical Review Research</em> 2 (4): 043271.
</div>
<div id="ref-zondervan2017priors" class="csl-entry" role="listitem">
Zondervan-Zwijnenburg, Mariëlle, Margot Peeters, Sarah Depaoli, and Rens Van de Schoot. 2017. <span>“Where Do Priors Come from? Applying Guidelines to Construct Informative Priors in Small Sample Research.”</span> <em>Research in Human Development</em> 14 (4): 305–20.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The permutations of <span class="math inline">\(b\)</span> must respect the model’s constraints; in most cases, this means that <span class="math inline">\(b\)</span> cannot contain any empty blocks.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>It should be noted that Bayesian inference also uses parameters, but generally reserves the moniker for a specific class of model setting that is both fixed and known. Prior probability distributions almost always take the form of parameterized distributions, such as the Gaussian, Poisson, Binomial, or Exponential distributions. In the context of a model, a Gaussian distribution with <span class="math inline">\(\mu\)</span>=1 (location) and <span class="math inline">\(\sigma\)</span>=2 (scale) represents a perfectly valid prior probability for an unobserved latent variable: in this way, Bayesian models frequently use parameters to describe prior uncertainty, despite the parameters themselves being known and fixed.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>This is not always the case, as some models/applications are better served by wholly uninformative priors, such as a flat prior, or an improper prior such as Jeffries’ prior. Conversely, some models may use strongly informative priors, which may constrain model behaviour <span class="citation" data-cites="zondervan2017priors">(<a href="#ref-zondervan2017priors" role="doc-biblioref">Zondervan-Zwijnenburg et al. 2017</a>)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>The number of hypotheses contained in a discrete latent variable is countable, whereas the number of hypotheses in a continuous latent variable is un-countably infinite.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>The term ‘well-specified’, here, is left intentionally ambiguous. Not all prior distributions lend themselves to meaningful output in the simulative mode, and flat/improper priors tend to dramatically limit the utility of a Bayesian model <span class="citation" data-cites="mcelreath2020statistical">(<a href="#ref-mcelreath2020statistical" role="doc-biblioref">McElreath 2020</a>)</span>. As such, the merit of Bayesian model simulation depends on good prior specification, a topic that is well beyond the scope of this chapter. Interested readers are encouraged to consult the ‘Prior Choice Recommendations’ page in <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">the stan GitHub repository</a>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Bayesian model invertability is made more intuitive, we find, when considered in light of the fact that one model’s posterior is another model’s prior – the only distinction is the amount of information encoded.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Namely, one that has all of its probability mass or density on the observed value.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>For more detail on this aspect of specifying BSBMs, see Peixoto (2019).<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Since we are only interested in modelling block membership, we are able to greatly simplify our task through the use of a ‘microcanonical model’ <span class="citation" data-cites="peixoto2019bayesian">(<a href="#ref-peixoto2019bayesian" role="doc-biblioref">Peixoto 2019</a>)</span>. Borrowed from the field of physics, microcanonical modelling permits models to sort their parameters into those with ‘hard’ constraints, and those with ‘soft’ constraints. By treating invariant aspects of the network – such as inter-block edge counts – as fixed parameters, we can avoid (potentially intractable) summation and integration signs in our model specification.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>At this stage, the mathematical model is not yet complete, as the statement of likelihood is not yet directly computable. Since the purpose of this chapter is to introduce readers to BSBMs, we have elided the model’s grittier mathematical detail. See Peixoto (2019) for the full specification.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>One or two explanations of the data may predominate over the others, but a Bayesian model never formally discards any hypothesis with a posterior probability greater than 0.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>The same principle can be found in the other information criteria briefly discussed in the previous paragraph, AIC and BIC.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>In what should be a familiar refrain by now, readers who are interested in the technical aspects of Hierarchical BSBMs should consult Peixoto <span class="citation" data-cites="peixoto2019bayesian peixoto2023descriptive">(<a href="#ref-peixoto2019bayesian" role="doc-biblioref">2019</a>, <a href="#ref-peixoto2023descriptive" role="doc-biblioref">2023</a>)</span>.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Our investigation left us reasonably confident that our corrections were sound, but also surprised us with the discovery of job titles that have not appeared in any other dataset to date. We wound up with only five completely uninformative “employee” titles remaining, as compared to the best case of 25 in the other datasets that we found. Nonetheless, we by no means claim to have achieved 100% accuracy, given how many other researchers have had a chance to do the same. The authors welcome and encourage any suggested corrections to this dataset. The Enron email corpus is still one of the only public datasets of corporate emails, in a world increasingly rich with such email data – most of latter will never be seen by academic network analysts.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>The implementation of BSBMs in Python’s graph-tool can incorporate as many edge covariates as you like into the Bayesian process, beyond the standard edge weights. Including too many covariates does tend to considerably increase both computation time and the number of blocks. The weighted results for Enron tend to be a bit less visibly intuitive on most model runs, but this might mean that they are better representing some process not determined by job title.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>This refinement process tends to consistently improve the MDL of a model by some amount, however small, but of course this doesn’t tell us whether the model is good; it merely tells us that it has outperformed its compatriots.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>See <a href="https://github.com/fivethirtyeight/russian-troll-tweets/" class="uri">https://github.com/fivethirtyeight/russian-troll-tweets/</a>.<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>Such as Barack Obama being born in Kenya. More recently, these accounts post about Covid-19 conspiracies.<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@incollection{browne2023,
  author = {Browne, Pierson and Crick, Tyler and McLevey, John},
  editor = {McLevey and John Scott and Peter J Carrington (eds), John},
  publisher = {SAGE},
  title = {Inferential {Network} {Clustering} with {Hierarchical}
    {Bayesian} {Stochastic} {Blockmodels}},
  booktitle = {The Sage Handbook of Social Network Analysis (Volume 2)},
  date = {2023-12-18},
  address = {London, UK},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-browne2023" class="csl-entry quarto-appendix-citeas" role="listitem">
Browne, Pierson, Tyler Crick, and John McLevey. 2023. <span>“Inferential
Network Clustering with Hierarchical Bayesian Stochastic
Blockmodels.”</span> In <em>The Sage Handbook of Social Network Analysis
(Volume 2)</em>, edited by John McLevey and John Scott and Peter J
Carrington (eds). London, UK: SAGE.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"openEffect":"zoom","loop":false,"descPosition":"bottom","closeEffect":"zoom","selector":".lightbox"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




</body></html>